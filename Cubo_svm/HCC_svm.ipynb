{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from fix_data import add_label_T\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcc_smarts_df_train = pd.read_csv(\"data/SmartSeq/HCC1806_SmartS_Filtered_Normalised_3000_Data_train.txt\", sep = \" \")\n",
    "mcf_smarts_df_train = pd.read_csv(\"data/SmartSeq/MCF7_SmartS_Filtered_Normalised_3000_Data_train.txt\", sep= \" \")\n",
    "\n",
    "hcc_smarts_df_train = add_label_T(hcc_smarts_df_train)\n",
    "mcf_smarts_df_train = add_label_T(mcf_smarts_df_train)\n",
    "\n",
    "X1 = hcc_smarts_df_train.loc[:,hcc_smarts_df_train.columns!='label']\n",
    "X2 = mcf_smarts_df_train.loc[:,mcf_smarts_df_train.columns!='label']\n",
    "y = hcc_smarts_df_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 98.3333%\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "cross = cross_val_score(svm, X1, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyeperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "180 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.98333333        nan 0.98333333 0.96726727 0.96156156\n",
      "        nan        nan        nan 0.98333333        nan 0.98333333\n",
      " 0.96696697 0.96711712        nan        nan        nan 0.98333333\n",
      "        nan 0.98333333 0.97237237 0.96711712        nan        nan\n",
      "        nan 0.98333333        nan 0.98333333 0.99444444 0.96711712\n",
      "        nan        nan        nan 0.98333333        nan 0.98333333\n",
      " 0.99444444 0.96711712        nan        nan        nan 0.98333333\n",
      "        nan 0.98333333 0.99444444 0.96711712        nan        nan\n",
      "        nan 0.98333333        nan 0.98333333 0.97807808 0.96711712\n",
      "        nan        nan        nan 0.98333333        nan 0.98333333\n",
      " 0.85750751 0.96711712        nan        nan        nan 0.98333333\n",
      "        nan 0.98333333 0.82957958 0.96711712        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1', 'l2'], \n",
    "          'loss':['squared_hinge', 'hinge'],\n",
    "          \"C\": [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000],\n",
    "          'dual': [True, False]\n",
    "            }\n",
    "\n",
    "gs_t = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X1, y)\n",
    "gs_t.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10000</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>10000</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual  mean_test_score  \\\n",
       "36       1  squared_hinge            l1      False         0.994444   \n",
       "28     0.1  squared_hinge            l1      False         0.994444   \n",
       "44      10  squared_hinge            l1      False         0.994444   \n",
       "67   10000          hinge            l2       True         0.983333   \n",
       "65   10000  squared_hinge            l2       True         0.983333   \n",
       "..     ...            ...           ...        ...              ...   \n",
       "63    1000          hinge            l2      False              NaN   \n",
       "64   10000  squared_hinge            l1       True              NaN   \n",
       "66   10000          hinge            l1       True              NaN   \n",
       "70   10000          hinge            l1      False              NaN   \n",
       "71   10000          hinge            l2      False              NaN   \n",
       "\n",
       "    rank_test_score  \n",
       "36                1  \n",
       "28                1  \n",
       "44                1  \n",
       "67                4  \n",
       "65                4  \n",
       "..              ...  \n",
       "63               37  \n",
       "64               37  \n",
       "66               37  \n",
       "70               37  \n",
       "71               37  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_t = pd.DataFrame(gs_t.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_t.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_t.iloc[:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1e-05': 0.9833333333333334,\n",
       " '0.0001': 0.9833333333333334,\n",
       " '0.001': 0.9833333333333334,\n",
       " '0.1': 0.9944444444444445,\n",
       " '1': 0.9944444444444445,\n",
       " '10': 0.9944444444444445,\n",
       " '100': 0.9833333333333334,\n",
       " '1000': 0.9833333333333334,\n",
       " '10000': 0.9833333333333334}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fit_true = {}\n",
    "for i in [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000]:\n",
    "    best_fit_true[f\"{i}\"] = max([svm_res_t.iloc[j,:].values for j in range(svm_res_t.shape[0]) if svm_res_t.iloc[j,0] == i], key= lambda x: x[4])[4]\n",
    "\n",
    "best_fit_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAHSCAYAAAB7FNs/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7aElEQVR4nO3de5hWZb038O/iIGiOUh4w8YAYWihmiCmVSmqAp5TXFPBV0kzLPOzXFHdlmpvSIHO799atW0xD7HKDWhQe8rDdlpUmaOIJt4rKLsTU8MDBBAfW+8eMIwjjDMMAw6zP57qeq3W477XuZ348TzNf77VWUZZlAAAAAGjfOqzrAQAAAACw5gmBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAI6rasTb7755mXPnj3X1ekBAAAA2p2HH374b2VZbrGyfessBOrZs2ceeuihdXV6AAAAgHanKIr/bWyfy8EAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKACmgyBiqK4tiiKV4qieKKR/UVRFP9WFMXMoigeK4qiX+sPEwAAAIDV0ZyZQOOTDPmA/Qcl6V3/OjnJlas/LAAAAABaU5MhUFmW9yV57QOaHJ5kQlnnj0m6FUXx0dYaIAAAAACrr1MrHKNHkr8ssz67fttL729YFMXJqZstlB49emTWrFmtcHoAAAAAmtIaIVCzlWU5Lsm4JOnfv3/Zs2fPtXl6AAAAgMpqjaeDvZhk22XWt6nfBgAAAEAb0RozgaYkOa0oiolJ9kryZlmWK1wKBgA07rRLP9bivpefObMVR0JrU9v2S20BWN80GQIVRfGfSQYm2bwoitlJvpekc5KUZfkfSW5PcnCSmUneSnLCmhosAAAAAC3TZAhUluWIJvaXSU5ttREBAAAA0Opa455AAAAAALRxa/XpYO3V4O/f1uK+d553SIv7FicVLe5bXl22uG+VqG371tL6qm3btz5+dk/ts2OL+1aJ2rZv66K+art2rI+fXf+/2zxq276tb/VV26aZCQQAAABQAWYCAQAAvI+nvwHtkZlAAAAAABUgBAIAAACoAJeDAawnTEsHAABWh5lAAAAAABVgJlBFtXRGgdkEzVcULX9sZb7a8q5mi6x566q2rB3q236pbfvW4vqqbZvns9t+qW37pr5tk5lAAAAAABUgBFrHiqJo8QsAAACguYRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFdFrXAwAAAIC15bRLP9bivpefObMVRwJrn5lAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKiATut6AAAAAACr67RLP9bivpefObMVR9J2mQkEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACqgWSFQURRDiqJ4uiiKmUVRfGsl+7criuLeoigeKYrisaIoDm79oQIAAADQUk2GQEVRdEzy70kOStInyYiiKPq8r9l3k9xYluWnkgxPckVrDxQAAACAlmvOTKBPJ5lZluXzZVkuTjIxyeHva1Mm2aR+edMkc1pviAAAAACsrk7NaNMjyV+WWZ+dZK/3tbkgyV1FUZye5ENJDmyV0QEAAADQKpoTAjXHiCTjy7K8pCiKAUmuL4pi17Isly7bqCiKk5OcnCQ9evTIrFmzWun061afjyxtulFjBg1qed/tWt61R80WLerXXmrWXFWqbaK+zaa2bZ7Pbvultu3bOqmv2q4VPrvtl9q2b+tbfdW2ac0JgV5Msu0y69vUb1vWiUmGJElZlg8URdE1yeZJXlm2UVmW45KMS5L+/fuXPXv2bNmo25gZrz3Z4r533XVXy0+8Gl98vTfesUX92kvNmqtKtU3Ut7nUtu3z2W2/1LZ9Wyf1Vdu1wme3/VLb9m19q6/aNq059wSalqR3URQ7FEWxQepu/DzlfW3+nOSAJCmK4hNJuiZ5tTUHCgAAAEDLNRkClWVZm+S0JHcmeSp1TwF7siiK0UVRfLG+2VlJTiqK4tEk/5nk+LIsyzU1aAAAAABWTbPuCVSW5e1Jbn/ftvOXWZ6R5LOtOzQAAAAAWktzLgcDAAAAYD0nBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACogGaFQEVRDCmK4umiKGYWRfGtRtocXRTFjKIoniyK4obWHSYAAAAAq6NTUw2KouiY5N+TfCHJ7CTTiqKYUpbljGXa9E7y7SSfLcvy9aIotlxTAwYAAABg1TVnJtCnk8wsy/L5siwXJ5mY5PD3tTkpyb+XZfl6kpRl+UrrDhMAAACA1dGcEKhHkr8ssz67ftuydkqyU1EUfyiK4o9FUQxprQECAAAAsPqavBxsFY7TO8nAJNskua8oir5lWb6xbKOiKE5OcnKS9OjRI7NmzWql069bfT6ytOWdBw1qed/tWt61R80WLerXXmrWXFWqbaK+zaa2bZ7Pbvultu3bOqmv2q4VPrvtl9q2b+tbfdW2ac0JgV5Msu0y69vUb1vW7CQPlmX5TpIXiqJ4JnWh0LRlG5VlOS7JuCTp379/2bNnzxYOu22Z8dqTLe571113tfzEq/HF13vjHVvUr73UrLmqVNtEfZtLbds+n932S23bt3VSX7VdK3x22y+1bd/Wt/qqbdOacznYtCS9i6LYoSiKDZIMTzLlfW1+mbpZQCmKYvPUXR72fOsNEwAAAIDV0WQIVJZlbZLTktyZ5KkkN5Zl+WRRFKOLovhifbM7k8wtimJGknuTjCrLcu6aGjQAAAAAq6ZZ9wQqy/L2JLe/b9v5yyyXSb5Z/wIAAACgjWnO5WAAAAAArOeEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAV0KwQqCiKIUVRPF0UxcyiKL71Ae2OLIqiLIqif+sNEQAAAIDV1WQIVBRFxyT/nuSgJH2SjCiKos9K2tUk+YckD7b2IAEAAABYPc2ZCfTpJDPLsny+LMvFSSYmOXwl7b6fZGySt1txfAAAAAC0guaEQD2S/GWZ9dn12xoURdEvybZlWd7WimMDAAAAoJV0Wt0DFEXRIck/Jzm+GW1PTnJykvTo0SOzZs1a3dO3CX0+srTlnQcNannf7VretUfNFi3q115q1lxVqm2ivs2mtm2ez277pbbt2zqpr9quFT677Zfatm/rW33VtmnNCYFeTLLtMuvb1G97V02SXZP8piiKJNkqyZSiKL5YluVDyx6oLMtxScYlSf/+/cuePXu2fORtyIzXnmxx37vuuqvlJ16NL77eG+/Yon7tpWbNVaXaJurbXGrb9vnstl9q276tk/qq7Vrhs9t+qW37tr7VV22b1pzLwaYl6V0UxQ5FUWyQZHiSKe/uLMvyzbIsNy/LsmdZlj2T/DHJCgEQAAAAAOtOkyFQWZa1SU5LcmeSp5LcWJblk0VRjC6K4otreoAAAAAArL5m3ROoLMvbk9z+vm3nN9J24OoPCwAAAIDW1JzLwQAAAABYzwmBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKkAIBAAAAFABQiAAAACAChACAQAAAFSAEAgAAACgAoRAAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAChEAAAAAAFSAEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAc0KgYqiGFIUxdNFUcwsiuJbK9n/zaIoZhRF8VhRFPcURbF96w8VAAAAgJZqMgQqiqJjkn9PclCSPklGFEXR533NHknSvyzL3ZLcnORHrT1QAAAAAFquOTOBPp1kZlmWz5dluTjJxCSHL9ugLMt7y7J8q371j0m2ad1hAgAAALA6mhMC9Ujyl2XWZ9dva8yJSX69OoMCAAAAoHV1as2DFUVxbJL+SfZrZP/JSU5Okh49emTWrFmtefp1ps9Hlra886BBLe+7Xcu79qjZokX92kvNmqtKtU3Ut9nUts3z2W2/1LZ9Wyf1Vdu1wme3/VLb9m19q6/aNq05IdCLSbZdZn2b+m3LKYriwCTnJtmvLMtFKztQWZbjkoxLkv79+5c9e/Zc1fG2STNee7LFfe+6666Wn3g1vvh6b7xji/q1l5o1V5Vqm6hvc6lt2+ez236pbfu2TuqrtmuFz277pbbt2/pWX7VtWnMuB5uWpHdRFDsURbFBkuFJpizboCiKTyW5KskXy7J8pfWHCQAAAMDqaDIEKsuyNslpSe5M8lSSG8uyfLIoitFFUXyxvtnFSTZOclNRFNOLopjSyOEAAAAAWAeadU+gsixvT3L7+7adv8zyga08LgAAAABaUXMuBwMAAABgPScEAgAAAKgAIRAAAABABQiBAAAAACpACAQAAABQAUIgAAAAgApo1iPi15Z33nkns2fPzttvv72uh7JKvn3gR1vc98w9f93yE2/c8q41nVtW+qeeeqrlJ23junbtmm222SadO3de10MBAACAVtemQqDZs2enpqYmPXv2TFEU63o4zdZxzhst7jtvztKWn3jzlnfdcsMuLeq3XfdPtPykbVhZlpk7d25mz56dHXbYYV0PBwAAAFpdm7oc7O23385mm222XgVAtA9FUWSzzTZb72ahAQAAQHO1qRAoiQCIdca/PQAAANqzNhcCAQAAAND62tQ9gd5v+D/fndcXLm614334Qxtk4je/8IFtNt544yxYsCDTp0/PKaecknnz5qVjx44599xzM2zYsEb77b/Xbrn51/fmIx/ZbLnt99x1e5575umcfNqZrfIemmvO7Dk588QzM+nOSS3qP2zoV3Lu987Kbrvv0sojAwAAANaFNh0CtWYAtKrH22ijjTJhwoT07t07c+bMyR577JHBgwenW7duq3TOAwYdnAMGHbyKIwUAAABoXW06BFqXdtppp4blrbfeOltuuWVeffXVDwyBfnbtuNx79x2prX0n/3LV+Oz4sZ3yi0k35InHHsn5F16cb/2/b2Tjmpo88egjefXVVzLq3H/KZ/rtkqVLl+ZHP/pRHnrooXTv3j2dOnXKF7/4xRxwwAF56qmncumll+bvf/97unXrlu9973vZfPOVPxbsqcefyvfP+X6SZK999mrYfsvNt+Spx57KOaPPSZKceeKZOe3UEzLgs3vm3HO+n0enP5m3316Ugw89MN8859RW+OkBAAAAbY17AjXD1KlTs3jx4uy4444f2O7DH9ksk+/8bYYf95Vc+x+Xr7TNKy+/nBt+eUeuum5iLvnhPyVJ7r333rz00ku58cYb80//9E95/PHHkyS1tbW5+OKLM3bs2Fx//fU57LDDcsUVVzR6/tGjRufsC87ODb++odnvbdS3z8itd03MnffenAcfeDhPzXim2X0BAACA9YeZQE146aWXctxxx+W6665Lhw4fnJkNOujQJMmuu+2eu39960rbHDjk4HTo0CEf2+nj+durryZJpk+fngMOOCAdOnTI5ptvnj322CNJMmvWrDz//PM59dS62TlLly5tdBbQ/HnzM3/+/PTbq1+S5OChB+f+397f5Pu7dcqdueFnN2dJ7ZK88vLf8uwzz+UTfXZqsh8AAACwfhECfYB58+blkEMOyYUXXpi99967yfadu3RJknTo2DFLltSutM0GG3R5b6Usmzxmr169cu211zZvwI3o2LFjlpZLG9YXLVqUJPnz/87OuCuvyy13/Gc27bZJzjrju1n0duvehwkAAABoG1wO1ojFixdn6NChGTlyZL70pS+t0XN98pOfzL333pulS5dm7ty5+dOf/pQk2X777fP666/nscceS1J3edhzzz230mPUbFKTmpqaTJ82PUlyx6/uaNi39TZb55kZz2Tp0qX565y/ZsajM5IkCxYszEYbbZiaTTbOq6/OzW/++/dr8F0CAAAA61Kbngn04Q9t0OqPiG+uG2+8Mffdd1/mzp2b8ePHJ0nGjx+f3XffvdXG8679998/06ZNy9FHH53u3btn5513zsYbb5zOnTtnzJgxueSSS7JgwYLU1tZmxIgRjd6b6PyLz6+7MXSR7L3PezOXPtn/k9l6261z9BeOzg4f2yE777JzkqTPLjtnl10/nv0/d3g+unX37PHpT7X6ewMAAADahjYdAk385hfW+jkXLFiQJDn22GNz7LHHNrvffz/4WMNy309+KtffXHdPoP8z7Jj8n2HHJEnG/MvyN3V+5NnZmTdnZjp06JB/+Id/yEYbbZQ33ngjxx9/fEPQs/POO2fcuHHNGsMn+n5iuZtCn/HtM5IkRVHkB//yg+Xabrlh3WVpl/zb8tvfNWny6l2CBgAAALQtbToEqpIzzzwz8+fPT21tbU488cRGbwANAAAA0BJCoFU0dOjQvPDCC8ttO/2c87LPwANW67hXXXVVs9uOHTs2jz766HLVG37C8HzxqC+u1hgAAACA9ksItIomT568wrZn5ryxVsfwj//4j3ULJgsBAAAAzeTpYAAAAAAVIAQCAAAAqAAhEAAAAEAFCIEAAAAAKqBNh0BbbbVViqJotddWW23V5Dk33njjJMn06dMzYMCA7LLLLtltt90yadKkNf12W92c2XMybPCwRvffNPFXOe/bF61035eP+UbefHPemhpai3z1q1/NjBkzVvs4s2bNyq677toKIwIAAID1R5t+OtjLL7+8zo630UYbZcKECendu3fmzJmTPfbYI4MHD063bt1adUwtUVtbm06d1mzprrvhijV6/FW1ZMmS/OQnP1nXwwAAAID1VpueCbQu7bTTTundu3eSZOutt86WW26ZV199tdH2P77oghw8cO8cduBnM3b0eUmSv/z5fzPssEE57IDP5NKxP8inem+TJHnw/t/nayPfm6Hzox/9KLfcckuS5Oqrr87IkSMzbNiwXHjhhSnLMknyta99LZdccklGjhyZiRMn5qmnnsrJw07OcYcdl9NHnp6/vfK3JMlTjz+VYw46JsccdExumnBTk+/z5ZdfzcgRX89+Aw7NRaP/uWH7Z/sPyWtzX89f/vxi9t/n8PzjWRfkwH2HZtCgQfn73/+eJJk2bVp222237L777hk1alTD7JolS5Zk1KhR2XPPPbPbbrvlqquuavT8v/nNb7LvvvvmkEMOyc4775yvf/3rWbp0aZK6WVlnnXVWPvnJT+aBBx7IwIED89BDDzXsGzVqVHbZZZcceOCBmTp1agYOHJhevXplypQpSepm/Oyzzz7p169f+vXrl/vvv7/JnwcAAAC0V0KgZpg6dWoWL16cHXfccaX7X3/ttdz969ty270P5Jb/+kNO+YezkyQXnv+tjBj5ldxyz/3Zsnv3Zp3r6KOPzoQJEzJp0qQsWrQov/vd7xr2vfPOO5kwYUKGDx+eiy++OGOvGJvrb7k+hx19WK74cd3MndGjRufsC87ODb++oVnnm/HE/+Tyqy7Onff+PLf+6s7MefGvK7SZ9fyfM/KE4fmv+yanW7du+fnPf54kOeGEE3LVVVdl+vTp6dixY0P7a665JptuummmTZuWadOm5eqrr84LL7zQ6BimTp2ayy67LDNmzMhzzz2XX/ziF0mShQsXZq+99sqjjz6az33uc8v1WbhwYfbff/88+eSTqampyXe/+93cfffdmTx5cs4///wkyZZbbpm77747f/rTnzJp0qScccYZzfqZAAAAQHskBGrCSy+9lOOOOy4//elP06HDyn9cNZtski5duuQ7Z52eu26/JV033DBJ8si0B3PIEUcmSQ4/svF78yzr4YcfzvHHH5/hw4fnoYceyvPPP9+w7wtf+EKSuhkuzz//fE497tQcc/Axufbya/PKS69k/rz5mT9/fvrt1S9JcvDQg5s832f32SubbFKTrl275GM79cqLs+es0Gbb7Xpkl10/niTZY489MmvWrLzxxhuZP39+BgwYkCQ55phjGtrfddddmTBhQnbffffstddemTt3bp599tlGx/DpT386vXr1SseOHTNixIj8/ve/T5J07NgxRx555Er7bLDBBhkyZEiSpG/fvtlvv/3SuXPn9O3bN7NmzUpSF5qddNJJ6du3b4466qhWuZ8QAAAArK/a9D2B1rV58+blkEMOyYUXXpi999670XadOnXKzbfdkwd+/9vccduU/OynV2fCTXWXJBVFsUL7jp06Zmm5tGF98eLFSZJFixZl7Nixue6667LVVltl3LhxDfuSZMP6cClJevXqlWunXLvccefPm7/K73GDDTZ4b1wdO6a2dslK2nRers27l4M1pizLXHbZZRk8eHCzxvD+n9G76127dl1uhtGyOnfu3NCuQ4cO6dKlS8NybW1tkuTSSy9N9+7d8+ijj2bp0qXp2rVrs8YDAAAA7ZGZQI1YvHhxhg4dmpEjR+ZLX/rSB7ZduHBB5s+fl/0OGJTvXHBhnp7xRJLkU3vuldt+VXfp1JRfvHd/nh49ts1zzzydxYsWZf78+Zk2bVrDOZOkW7dueeutt3LPPfes9Hzbb799Xn/99Tz2p8eSJLXv1Oa5Z55LzSY1qampyfRp05Mkd/zqjpb/AJrQrVu31NTU5MEHH0ySTJw4sWHf4MGDc+WVV+add95JkjzzzDNZuHBho8eaOnVqXnjhhSxdujSTJk1a4dKvlnrzzTfz0Y9+NB06dMj111+fJUtWDLgAAACgKtr0TKDu3bu36hPCujfzvjxJcuONN+a+++7L3LlzM378+CTJ+PHjs/vuu6/QduGCBfnGV/5vFi16OynLfOt7FyZJzh09JmefelJ+csW/Zv9B712a9dEe22TIYUfk0P0/k626b5GddtopSVJTU5Mjjjgiw4cPz2abbZY+ffqsdGydO3fOmDFjcsmYS7Jg/oLULqnNiBNGZMeddsz5F5+f75/z/aRI9t6n8dlLreGaa67JSSedlA4dOmS//fbLpptumqTuUe6zZs1Kv379UpZltthii/zyl79s9Dh77rlnTjvttMycOTOf//znM3To0FYZ3ze+8Y0ceeSRmTBhQoYMGZIPfehDrXJcAAAAWB+16RDor39d8SbFa9qCBQuSJMcee2yOPfbYZvXZsvtWufm2FWftbLvd9pl0y10N6xN+8h8Ny+d8d3TO+e7ozJszc7k+p5xySk455ZQVjvX+J2ztvPPOGXfjuBXafaLvJ5a7KfQZ3278ZshHDT88Rw0/vGH9pz+7vGH5Dw/VzSL6yGYfzt2/ndyw/eyzz25Y3mWXXfLYY3WzkcaMGZP+/fsnqbsk66KLLspFF13U6LmXtckmm+TWW29dYfu7tXjXb37zm5Xuu+CCC1bar3fv3g3jS5KxY8cmSXr27JknnniiWWMDAACA9qJNh0C0bbfddlt++MMfpra2Nttvv33DjCkAAACg7RECraKhQ4eu8Ljz0885L/sMPKDJvo88O3tNDesDPfDbB3LZ2MuW29ar57YZ99N/Wa3jDhs2LMOGNe+pZ48//niOO+645bZ16dIlDz74YAYOHLha4wAAAACaJgRaRZMnT15h2zNz3lj7A1kFA/YbkAH7DVhu25YbdlmrY+jbt2+mT5++Vs8JAAAAvMfTwQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVECbvjH0VmdtlZfnvdxqx+u+Sff89ZK/fmCbjTfeOAsWLMj06dNzyimnZN68eenYsWPOPffcZj8Jq62YM3tOzjzxzEy6c9JK99808Vd57NEn8/0ffmeFfV8+5hv5tyvHZNNNN1nTw1zO8ccfn0MPPTRf+tKXVrnvb37zm/z4xz/OrbfeugZGBgAAAOu3Nh0CtWYAtKrH22ijjTJhwoT07t07c+bMyR577JHBgwenW7durTqmlqitrU2nTmu2dNfdcMUaPT4AAACwdrkcrBE77bRTevfunSTZeuuts+WWW+bVV19ttP2PL7ogBw/cO4cd+NmMHX1ekuQvf/7fDDtsUA474DO5dOwP8qne2yRJHrz/9/nayPdmFf3oRz/KLbfckiS5+uqrM3LkyAwbNiwXXnhhyrJMknzta1/LJZdckpEjR2bixIl56qmncvKwk3PcYcfl9JGn52+v/C1J8tTjT+WYg47JMQcdk5sm3NTk+3z55VczcsTXs9+AQ3PR6H9u2P7Z/kPy2tzX85c/v5j99zk8/3jWBTlw36EZNGhQ/v73vydJpk2blt122y277757Ro0alV133TVJsmTJkowaNSp77rlndtttt1x11VWNnr8sy5x22mnZeeedc+CBB+aVV15p2NezZ8/87W917+uhhx7KwIEDkyRTp07NgAED8qlPfSqf+cxn8vTTTzf5PgEAAKDqhEDNMHXq1CxevDg77rjjSve//tprufvXt+W2ex/ILf/1h5zyD2cnSS48/1sZMfIrueWe+7Nl9+7NOtfRRx+dCRMmZNKkSVm0aFF+97vfNex75513MmHChAwfPjwXX3xxxl4xNtffcn0OO/qwXPHjupk7o0eNztkXnJ0bfn1Ds84344n/yeVXXZw77/15bv3VnZnz4oqXy816/s8ZecLw/Nd9k9OtW7f8/Oc/T5KccMIJueqqqzJ9+vR07Nixof0111yTTTfdNNOmTcu0adNy9dVX54UXXljp+SdPnpynn346M2bMyIQJE3L//fc3OeaPf/zj+d3vfpdHHnkko0ePzne+s+LlbAAAAMDy2vTlYG3BSy+9lOOOOy7XXXddOnRYeWZWs8km6dKlS75z1un5/IGDM/DAwUmSR6Y9mMuunpAkOfzIYfnxhf/U5PkefvjhTJgwIW+//XbmzZuXXr16Zd99902SfOELX0iSzJo1K88//3xOPe7UJMnSpUuz+RabZ/68+Zk/f3767dUvSXLw0INz/28/OFT57D57ZZNNapIkH9upV16cPSdb99hquTbbbtcju+z68STJHnvskVmzZuWNN97I/PnzM2DAgCTJMccc03AvnrvuuiuPPfZYbr755iTJm2++mWeffTY77LDDCue/7777MmLEiHTs2DFbb7119t9//yZ/Rm+++Wa+/OUv59lnn01RFHnnnXea7AMAAABVJwT6APPmzcshhxySCy+8MHvvvXej7Tp16pSbb7snD/z+t7njtin52U+vzoSbpiRJiqJYoX3HTh2ztFzasL548eIkyaJFizJ27Nhcd9112WqrrTJu3LiGfUmy4YYbNiz36tUr1065drnjzp83f5Xf4wYbbPDeuDp2TG3tkpW06bxcm3cvB2tMWZa57LLLMnjw4FUez7I6deqUpUvrfk5vv/12w/bzzjsvn//85zN58uTMmjWr4TIxAAAAoHEuB2vE4sWLM3To0IwcObLJJ1UtXLgg8+fPy34HDMp3LrgwT894IknyqT33ym2/qrt0asov3rs/T48e2+a5Z57O4kWLMn/+/EybNq3hnEnSrVu3vPXWW7nnnntWer7tt98+r7/+eh7702NJktp3avPcM8+lZpOa1NTUZPq06UmSO351R8t/AE3o1q1bampq8uCDDyZJJk6c2LBv8ODBufLKKxtm6DzzzDNZuHDhSo+z7777ZtKkSVmyZEleeuml3HvvvQ37evbsmYcffjhJGi5BS+pmAvXo0SNJMn78+FZ9XwAAANBetemZQN036d7qj4hvrhtvvDH33Xdf5s6d2xA0jB8/PrvvvvsKbRcuWJBvfOX/ZtGit5OyzLe+d2GS5NzRY3L2qSflJ1f8a/YfdHBD+4/22CZDDjsih+7/mWzVfYvstNNOSZKampocccQRGT58eDbbbLP06dNnpWPr3LlzxowZk0vGXJIF8xekdkltRpwwIjvutGPOv/j8fP+c7ydFsvc+jc9eag3XXHNNTjrppHTo0CH77bdfNt100yTJV7/61cyaNSv9+vVLWZbZYost8stf/nKlxxg6dGj++7//O3369Ml2223XcHlZknzve9/LiSeemPPOO2+52T7nnHNOvvzlL+cHP/hBDjnkkDX5FgEAAKDdaNMh0F8vWfEmxWvaggULkiTHHntsjj322Gb12bL7Vrn5thVn7Wy73faZdMtdDesTfvIfDcvnfHd0zvnu6MybM3O5PqecckpOOeWUFY71/ids7bzzzhl347gV2n2i7yeWuyn0Gd8+o9FxHzX88Bw1/PCG9Z/+7PKG5T88VDeL6CObfTh3/3Zyw/azzz67YXmXXXbJY4/VzUYaM2ZM+vfvnyTp0KFDLrroolx00UWNnvtdRVHk8ssvX+m+ffbZJ88888wK2wcMGLDc9h/84AdJkoEDB7o0DAAAABrRpkMg2rbbbrstP/zhD1NbW5vtt9/epVkAAADQhgmBVtHQoUNXeNz56eecl30GHtBk30eenb2mhvWBHvjtA7ls7GXLbevVc9uM++m/rNZxhw0blmHDhjWr7eOPP57jjjtuuW1dunRpuKcQAAAAsGYJgVbR5MmTV9j2zJw31v5AVsGA/QZkwH4Dltu25YZd1uoY+vbtm+nTp6/VcwIAAADv8XQwAAAAgAoQAgEAAABUgBAIAAAAoAKEQAAAAAAV0KZvDP3tq/bO/Lf+1mrHq9lo8/zwa3/8wDYbb7xxFixYkCQZMmRI/vjHP+Zzn/tcbr311lYbx9oyZ/acnHnimZl056SV7r9p4q/y2KNP5vs//M4K+758zDfyb1eOyaabbrKmh9lsX/3qV/PNb34zffr0Wa3jzJo1K4ceemieeOKJVhoZAAAAtH1tOgRqzQCoJccbNWpU3nrrrVx11VWtOo7VVVtbm06d1mzprrvhijV6/FW1ZMmS/OQnP1nXwwAAAID1lsvBPsABBxyQmpqaZrX98UUX5OCBe+ewAz+bsaPPS5L85c//m2GHDcphB3wml479QT7Ve5skyYP3/z5fGzmsoe+PfvSj3HLLLUmSq6++OiNHjsywYcNy4YUXpizLJMnXvva1XHLJJRk5cmQmTpyYp556KicPOznHHXZcTh95ev72Sl3A9dTjT+WYg47JMQcdk5sm3NTkuF9++dWMHPH17Dfg0Fw0+p8btn+2/5C8Nvf1/OXPL2b/fQ7PP551QQ7cd2gGDRqUv//970mSadOmZbfddsvuu++eUaNGZdddd01SF9iMGjUqe+65Z3bbbbcPDNF+85vfZN99980hhxySnXfeOV//+tezdOnSJHWzss4666x88pOfzAMPPJCBAwfmoYceatg3atSo7LLLLjnwwAMzderUDBw4ML169cqUKVOS1M342WeffdKvX7/069cv999/f5M/DwAAAGivhECt4PXXXsvdv74tt937QG75rz/klH84O0ly4fnfyoiRX8kt99yfLbt3b9axjj766EyYMCGTJk3KokWL8rvf/a5h3zvvvJMJEyZk+PDhufjiizP2irG5/pbrc9jRh+WKH9fN3Bk9anTOvuDs3PDrG5p1vhlP/E8uv+ri3Hnvz3Prr+7MnBf/ukKbWc//OSNPGJ7/um9yunXrlp///OdJkhNOOCFXXXVVpk+fno4dOza0v+aaa7Lppptm2rRpmTZtWq6++uq88MILjY5h6tSpueyyyzJjxow899xz+cUvfpEkWbhwYfbaa688+uij+dznPrdcn4ULF2b//ffPk08+mZqamnz3u9/N3XffncmTJ+f8889Pkmy55Za5++6786c//SmTJk3KGWec0ayfCQAAALRHQqBWULPJJunSpUu+c9bpuev2W9J1ww2TJI9MezCHHHFkkuTwI4d90CEaPPzwwzn++OMzfPjwPPTQQ3n++ecb9n3hC19IUjfD5fnnn8+px52aYw4+Jtdefm1eeemVzJ83P/Pnz0+/vfolSQ4eenCT5/vsPntlk01q0rVrl3xsp155cfacFdpsu12P7LLrx5Mke+yxR2bNmpU33ngj8+fPz4ABA5IkxxxzTEP7u+66KxMmTMjuu++evfbaK3Pnzs2zzz7b6Bg+/elPp1evXunYsWNGjBiR3//+90mSjh075sgjj1xpnw022CBDhgxJkvTt2zf77bdfOnfunL59+2bWrFlJ6kKzk046KX379s1RRx2VGTNmNPnzAAAAgPaqTd8TaH3RqVOn3HzbPXng97/NHbdNyc9+enUm3FR3SVJRFCu079ipY5aWSxvWFy9enCRZtGhRxo4dm+uuuy5bbbVVxo0b17AvSTasD5eSpFevXrl2yrXLHXf+vPmrPPYNNtjgvXF17Jja2iUradN5uTbvXg7WmLIsc9lll2Xw4MHNGsP7f0bvrnft2nW5GUbL6ty5c0O7Dh06pEuXLg3LtbW1SZJLL7003bt3z6OPPpqlS5ema9euzRoPAAAAtEdmArWChQsXZP78ednvgEH5zgUX5ukZdU+d+tSee+W2X9VdOjXlF+/dn6dHj23z3DNPZ/GiRZk/f36mTZuW5L0wqFu3bnnrrbdyzz33rPR822+/fV5//fU89qfHkiS179TmuWeeS80mNampqcn0adOTJHf86o418n7fHWNNTU0efPDBJMnEiRMb9g0ePDhXXnll3nnnnSTJM888k4ULFzZ6rKlTp+aFF17I0qVLM2nSpBUu/WqpN998Mx/96EfToUOHXH/99VmyZMWACwAAAKqiTc8Eqtlo81Z/RPyq2GefffI///M/WbBgQbbZZptcc801K53dsnDBgnzjK/83ixa9nZRlvvW9C5Mk544ek7NPPSk/ueJfs/+g9y7N+miPbTLksCNy6P6fyVbdt8hOO+1UN76amhxxxBEZPnx4Nttss0Yfhd65c+eMGTMml4y5JAvmL0jtktqMOGFEdtxpx5x/8fn5/jnfT4pk7332XqX3u6quueaanHTSSenQoUP222+/bLrppknqHuU+a9as9OvXL2VZZosttsgvf/nLRo+z55575rTTTsvMmTPz+c9/PkOHDm2V8X3jG9/IkUcemQkTJmTIkCH50Ic+1CrHBQAAgPVRmw6Bfvi1P671cy5YsKBhedmbMn+QLbtvlZtvW3HWzrbbbZ9Jt9zVsD7hJ//RsHzOd0fnnO+Ozrw5M5frc8opp+SUU05Z4Vjvf8LWzjvvnHE3jluh3Sf6fmK5m0Kf8e3Gb4Z81PDDc9TwwxvWf/qzyxuW//BQ3Syij2z24dz928kN288+++yG5V122SWPPVY3G2nMmDHp379/krpLsi666KJcdNFFjZ57WZtsskluvfXWFbYvW4uk7kliK9t3wQUXrLRf7969G8aXJGPHjk2S9OzZM0888USzxgYAAADtRZsOgWjbbrvttvzwhz9MbW1ttt9++4wfP35dDwkAAABohBBoFQ0dOnSFx52ffs552WfgAU32feTZ2WtqWB/ogd8+kMvGXrbctl49t824n/7Lah132LBhGTaseU89e/zxx3Pcccctt61Lly558MEHM3DgwNUaBwAAANA0IdAqmjx58grbnpnzxtofyCoYsN+ADNhvwHLbttywy1odQ9++fTN9+vS1ek4AAADgPW3u6WBlWa7rIVBR/u0BAADQnrWpEKhr166ZO3euP8ZZ68qyzNy5c9O1a9d1PRQAAABYI9rU5WDbbLNNZs+enVdffXVdD2WVvPzG31vc9+03/9byE7/d8q6LOres9Atfa1P/ZFpV165ds80226zrYQAAAMAa0ay/6IuiGJLkX5N0TPKTsizHvG9/lyQTkuyRZG6SYWVZzlrVwXTu3Dk77LDDqnZb5/7f929rcd+7zj+05Sf+asu7ntpnxxb1u/zMmU03AgAAANqcJi8HK4qiY5J/T3JQkj5JRhRF0ed9zU5M8npZlh9LcmmSsa09UAAAAABarjn3BPp0kpllWT5fluXiJBOTHP6+Nocnua5++eYkBxRFUbTeMAEAAABYHc0JgXok+csy67Prt620TVmWtUneTLJZawwQAAAAgNVXNPUkrqIovpRkSFmWX61fPy7JXmVZnrZMmyfq28yuX3+uvs3f3nesk5OcXL+6c5KnW+uNVNTmSVbjztK0cerbfqlt+6W27Zv6tl9q236pbfumvu2X2q6e7cuy3GJlO5pzY+gXk2y7zPo29dtW1mZ2URSdkmyauhtEL6csy3FJxjVnxDStKIqHyrLsv67HwZqhvu2X2rZfatu+qW/7pbbtl9q2b+rbfqntmtOcy8GmJeldFMUORVFskGR4kinvazMlyZfrl7+U5L/LpqYYAQAAALDWNDkTqCzL2qIoTktyZ+oeEX9tWZZPFkUxOslDZVlOSXJNkuuLopiZ5LXUBUUAAAAAtBHNuRwsZVnenuT29207f5nlt5Mc1bpDoxlcWte+qW/7pbbtl9q2b+rbfqlt+6W27Zv6tl9qu4Y0eWNoAAAAANZ/zbknEAAAAADrOSFQG1EUxbVFUbxSFMUTLei7R1EUjxdFMbMoin8riqKo335BURQvFkUxvf51cOuPnMYURTGkKIqn6+vyrZXs71IUxaT6/Q8WRdFzmX3frt/+dFEUg5s6ZlEUp9VvK4ui2HyNvzkarKE6t/j7gLWjGXXftyiKPxVFUVsUxZfWxRhpPT6T7cvK6lkUxUeKori7KIpn6//3w+tyjDTfqtSzqPNv9d/djxVF0W/djZyVaa16FkXx5fr2zxZF8eWVnYu1Y03XtLG/hWmcEKjtGJ9kSAv7XpnkpCS961/LHufSsix3r3/dvtLetLqiKDom+fckByXpk2REURR93tfsxCSvl2X5sSSXJhlb37dP6m6uvkvqanlFURQdmzjmH5IcmOR/1+gbYzlros71fcan5d8HrGHNrPufkxyf5Ia1OzrWkPHxmWxPxmfFen4ryT1lWfZOck/9OuuH8Wl+PQ/Ke78vn5y636FpW8ZnNetZFMVHknwvyV5JPp3ke4LddWp81mxNP+hvYVZCCNRGlGV5X+qerNagKIodi6K4oyiKh4ui+F1RFB9/f7+iKD6aZJOyLP9Y1t3gaUKSI9bKoPkgn04ysyzL58uyXJxkYpLD39fm8CTX1S/fnOSA+uT68CQTy7JcVJblC0lm1h+v0WOWZflIWZaz1vSbYgVros4r/T6gTWmy7mVZzirL8rEkS9fFAGldPpPtSyP1XPa7+rr4XWq9sYr1PDzJhLLOH5N0q/9dmjaileo5OMndZVm+Vpbl60nujmBgnVmTNfW3cMsIgdq2cUlOL8tyjyRnJ7liJW16JJm9zPrs+m3vOq1+Kt21EvC1qkeSvyyz/v66LNemLMvaJG8m2ewD+jbnmKxda6LOtH1qB+1P97IsX6pf/muS7utyMKy2xurp+3v9tKr1VOe2r7Vq2tTfwqyEEKiNKopi4ySfSXJTURTTk1yVZFX/S8WVSXZMsnuSl5Jc0opDBABod+r/a7LH57YT6tm+qGf7o6ZrnxCo7eqQ5I1l7ueze1mWn6i/N8y7N3oeneTFJNss02+b+m0py/LlsiyXlGW5NMnVqb/UhLXixSTbLrPeUJeVtSmKolOSTZPM/YC+zTkma9eaqDNtn9pB+/Pyu5cF1f/vK+t4PKyexurp+3v9tKr1VOe2r7Vq2ujfwjROCNRGlWU5L8kLRVEclTTcKf2T9aHOu6HQ+fXT6OYVRbF3/X1GRib5VX2fZWcODU3iqSZrz7QkvYui2KEoig1SdwPgKe9rMyXJu3e2/1KS/65PwqckGV7UPVVqh9Td4GxqM4/J2rUm6kzb57MI7c+y39VfTv3vUqy3GqvnlCQj63+v3jvJm8tckkLbtar1vDPJoKIoPlx/O4xB9dtoO1qlph/0tzAfoCxLrzbwSvKfqbtk653UXct4YpIdktyR5NEkM5Kc30jf/qkLeJ5LcnmSon779UkeT/JY6j5QH13X77NKryQHJ3mmvi7n1m8bneSL9ctdk9yUuhsCT03Sa5m+59b3ezrJQR90zPrtZ9T/u6lNMifJT9b1+6/Kaw3VeYXvg3X9Pr1Wue571tduYepmfj25rsfstVr19plsR69GfufaLHVPqHk2yX8l+ci6HqdX69czSZG6pzs+V/87cv91PX6vNVPPJF+p/91rZpIT1vX7qvJrTdc0jfwt7NX4692wAAAAAIB2zOVgAAAAABUgBAIAAACoACEQAAAAQAUIgQAAAAAqQAgEAAAAUAFCIAAAAIAKEAIBAAAAVIAQCAAAAKAC/j8OgaLfAVnftwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_res_t.sort_values(by=\"param_C\", ascending=True, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "\n",
    "\n",
    "ax.bar([i for i in range(0,18,2)], [i for k,i in  enumerate(svm_res_t.loc[:,\"mean_test_score\"]) if (svm_res_t.iloc[k, 1] == \"hinge\" and svm_res_t.iloc[k, 2] == \"l2\" and svm_res_t.iloc[k, 3] == True)], width= 0.25, color= \"steelblue\")\n",
    "ax.bar([i + 0.25 for i in range(0,18,2)], [i for k,i in  enumerate(svm_res_t.loc[:,\"mean_test_score\"]) if (svm_res_t.iloc[k, 1] == \"squared_hinge\" and svm_res_t.iloc[k, 2] == \"l2\" and svm_res_t.iloc[k, 3] == False)], width= 0.25, color= \"black\")\n",
    "ax.bar([i + 0.25 + 0.25 for i in range(0,18,2)], [i for k,i in  enumerate(svm_res_t.loc[:,\"mean_test_score\"]) if (svm_res_t.iloc[k, 1] == \"squared_hinge\" and svm_res_t.iloc[k, 2] == \"l2\" and svm_res_t.iloc[k, 3] == True)], width= 0.25, color= \"darkgreen\")\n",
    "ax.bar([i + 0.25 + 0.25 + 0.25 for i in range(0,18,2)], [i for k,i in  enumerate(svm_res_t.loc[:,\"mean_test_score\"]) if (svm_res_t.iloc[k, 1] == \"squared_hinge\" and svm_res_t.iloc[k, 2] == \"l1\" and svm_res_t.iloc[k, 3] == False)], width= 0.25, color= \"olivedrab\")\n",
    "\n",
    "ax.set_xticks([i + 0.385 for i in range(0,18,2)], [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000])\n",
    "\n",
    "ax.grid(axis= 'y', which= 'major', alpha=0.5)\n",
    "\n",
    "colors = {\"l2_hinge_dual\": \"steelblue\", \"l2_squared_hinge_primal\": \"black\", \"l2_squared_hinge_dual\": \"darkgreen\", \"l1_squared_hinge_primal\": \"olivedrab\"}\n",
    "label = list(colors.keys())\n",
    "handle = [plt.Rectangle((0,0),2,2, color=colors[lab]) for lab in label]\n",
    "\n",
    "ax.legend(handles= handle, labels= label, loc = \"lower left\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "180 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.98333333        nan 0.98333333 0.96726727 0.96156156\n",
      "        nan        nan        nan 0.98333333        nan 0.98333333\n",
      " 0.96696697 0.96711712        nan        nan        nan 0.98333333\n",
      "        nan 0.98333333 0.97252252 0.96711712        nan        nan\n",
      "        nan 0.98333333        nan 0.98333333 0.99444444 0.96711712\n",
      "        nan        nan        nan 0.98333333        nan 0.98333333\n",
      " 0.98888889 0.96711712        nan        nan        nan 0.98333333\n",
      "        nan 0.98333333 0.98888889 0.96711712        nan        nan\n",
      "        nan 0.98333333        nan 0.98333333 0.96726727 0.96711712\n",
      "        nan        nan        nan 0.98333333        nan 0.98333333\n",
      " 0.89564565 0.96711712        nan        nan        nan 0.98333333\n",
      "        nan 0.98333333 0.83543544 0.96711712        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(fit_intercept = False)\n",
    "p_grid = {'penalty': ['l1', 'l2'], \n",
    "          'loss':['squared_hinge', 'hinge'],\n",
    "          \"C\": [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000],\n",
    "          'dual': [True, False]\n",
    "            }\n",
    "\n",
    "gs_f = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X1, y)\n",
    "gs_f.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10000</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual  mean_test_score  \\\n",
       "0      0.1  squared_hinge            l1      False         0.994444   \n",
       "1        1  squared_hinge            l1      False         0.988889   \n",
       "2       10  squared_hinge            l1      False         0.988889   \n",
       "3    10000          hinge            l2       True         0.983333   \n",
       "4    10000  squared_hinge            l2       True         0.983333   \n",
       "..     ...            ...           ...        ...              ...   \n",
       "67    1000          hinge            l2      False              NaN   \n",
       "68   10000  squared_hinge            l1       True              NaN   \n",
       "69   10000          hinge            l1       True              NaN   \n",
       "70   10000          hinge            l1      False              NaN   \n",
       "71   10000          hinge            l2      False              NaN   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 2  \n",
       "3                 4  \n",
       "4                 4  \n",
       "..              ...  \n",
       "67               37  \n",
       "68               37  \n",
       "69               37  \n",
       "70               37  \n",
       "71               37  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_f = pd.DataFrame(gs_f.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_f.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_f.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_false = {}\n",
    "for i in [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000]:\n",
    "    best_fit_false[f\"{i}\"] = max([svm_res_f.iloc[j,:].values for j in range(svm_res_f.shape[0]) if svm_res_f.iloc[j,0] == i], key= lambda x: x[4])[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "ax.bar([i for i in range(9)], list(best_fit_true.values()), 0.25, color = \"black\")\n",
    "ax.bar([i + 0.25 for i in range(9)], list(best_fit_false.values()), 0.25, color = \"darkgreen\")\n",
    "\n",
    "ax.set_xticks([i + 0.125 for i in range(9)], [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000])\n",
    "ax.grid(axis= 'y', which= 'major', alpha=0.5)\n",
    "\n",
    "colors = {\"intercept_true\": \"black\", \"intercept_false\": \"darkgreen\"}\n",
    "label = list(colors.keys())\n",
    "handle = [plt.Rectangle((0,0),2,2, color=colors[lab]) for lab in label]\n",
    "\n",
    "ax.legend(handles= handle, labels= label, loc = \"lower left\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "160 fits failed out of a total of 640.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.98333333 0.98333333 0.98333333        nan 0.98333333\n",
      " 0.98333333 0.98333333 0.96141141 0.98888889 0.98333333 0.98333333\n",
      "        nan        nan 0.98333333 0.98333333        nan 0.98333333\n",
      " 0.98333333 0.98333333        nan 0.98333333 0.98333333 0.98333333\n",
      " 0.97792793 0.96711712 0.98333333 0.98333333        nan        nan\n",
      " 0.98333333 0.98333333        nan 0.98333333 0.98333333 0.98333333\n",
      "        nan 0.98333333 0.98333333 0.98333333 0.99444444 0.98333333\n",
      " 0.98333333 0.98333333        nan        nan 0.98333333 0.98333333\n",
      "        nan 0.98333333 0.98333333 0.98333333        nan 0.98333333\n",
      " 0.98333333 0.98333333 0.99444444 0.96711712 0.98333333 0.98333333\n",
      "        nan        nan 0.98333333 0.98333333        nan 0.98333333\n",
      " 0.98333333 0.98333333        nan 0.98333333 0.98333333 0.98333333\n",
      " 0.98888889 0.98333333 0.98333333 0.98333333        nan        nan\n",
      " 0.98333333 0.98333333        nan 0.98333333 0.98333333 0.98333333\n",
      "        nan 0.98333333 0.98333333 0.98333333 0.99444444 0.96711712\n",
      " 0.98333333 0.98333333        nan        nan 0.98333333 0.98333333\n",
      "        nan 0.98333333 0.98333333 0.98333333        nan 0.98333333\n",
      " 0.98333333 0.98333333 0.97807808 0.98333333 0.98333333 0.98333333\n",
      "        nan        nan 0.98333333 0.98333333        nan 0.98333333\n",
      " 0.98333333 0.98333333        nan 0.98333333 0.98333333 0.98333333\n",
      " 0.97267267 0.96711712 0.98333333 0.98333333        nan        nan\n",
      " 0.98333333 0.98333333]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': 'balanced',\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'loss': 'squared_hinge',\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1', 'l2'], \n",
    "          'loss':['squared_hinge', 'hinge'],\n",
    "          \"C\": [0.001, 0.1 , 1, 10],\n",
    "          'dual': [True, False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr', 'crammer_singer']\n",
    "            }\n",
    "\n",
    "gs_cr = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X1, y)\n",
    "gs_cr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>None</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>None</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>None</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0       1  squared_hinge            l1      False               ovr   \n",
       "1     0.1  squared_hinge            l1      False               ovr   \n",
       "2     0.1  squared_hinge            l1      False               ovr   \n",
       "3   0.001  squared_hinge            l2      False               ovr   \n",
       "4       1  squared_hinge            l1      False               ovr   \n",
       "5   0.001  squared_hinge            l2       True               ovr   \n",
       "6       1  squared_hinge            l2       True               ovr   \n",
       "7       1  squared_hinge            l1      False    crammer_singer   \n",
       "8       1          hinge            l2       True    crammer_singer   \n",
       "9       1          hinge            l1       True    crammer_singer   \n",
       "\n",
       "  param_class_weight  mean_test_score  rank_test_score  \n",
       "0               None         0.994444                1  \n",
       "1               None         0.994444                1  \n",
       "2           balanced         0.994444                1  \n",
       "3           balanced         0.988889                4  \n",
       "4           balanced         0.988889                4  \n",
       "5           balanced         0.983333                6  \n",
       "6               None         0.983333                6  \n",
       "7               None         0.983333                6  \n",
       "8               None         0.983333                6  \n",
       "9               None         0.983333                6  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_cr = pd.DataFrame(gs_cr.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_cr.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_cr.reset_index(drop= True, inplace=True)\n",
    "svm_res_cr.iloc[:10,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_59256/177650559.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Number of neighbours'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Distance vs Uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mean_test_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"crammer_singer\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"squared_hinge\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"l2\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"black\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mean_test_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ovr\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"hinge\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"l2\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"green\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"mean_test_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"crammer_singer\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"squared_hinge\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"l2\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msvm_res_cr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"brown\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1630\u001b[0m         \"\"\"\n\u001b[0;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    499\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (4,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_res_cr.sort_values(by=\"param_C\", ascending=True, inplace=True)\n",
    "svm_res_cr.reset_index(drop= True, inplace=True)\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.set(xlabel='Number of neighbours', ylabel='Accuracy', title='Distance vs Uniform')\n",
    "\n",
    "ax.plot([i for i in range(5)], [i for k,i in  enumerate(svm_res_cr.loc[:,\"mean_test_score\"]) if (svm_res_cr.iloc[k, 4] == \"crammer_singer\" and svm_res_cr.iloc[k, 1] == \"squared_hinge\" and svm_res_cr.iloc[k, 2] == \"l2\" and svm_res_cr.iloc[k, 3] == True and svm_res_cr.iloc[k, 5] == \"balanced\")], color= \"black\")\n",
    "ax.plot([i for i in range(5)], [i for k,i in  enumerate(svm_res_cr.loc[:,\"mean_test_score\"]) if (svm_res_cr.iloc[k, 4] == \"ovr\" and svm_res_cr.iloc[k, 1] == \"hinge\" and svm_res_cr.iloc[k, 2] == \"l2\" and svm_res_cr.iloc[k, 3] == True and svm_res_cr.iloc[k, 5] == \"balanced\")], color= \"green\")\n",
    "ax.plot([i for i in range(5)], [i for k,i in  enumerate(svm_res_cr.loc[:,\"mean_test_score\"]) if (svm_res_cr.iloc[k, 4] == \"crammer_singer\" and svm_res_cr.iloc[k, 1] == \"squared_hinge\" and svm_res_cr.iloc[k, 2] == \"l2\" and svm_res_cr.iloc[k, 3] == True and svm_res_cr.iloc[k, 5] == None)], color= \"brown\")\n",
    "ax.plot([i for i in range(5)], [i for k,i in  enumerate(svm_res_cr.loc[:,\"mean_test_score\"]) if (svm_res_cr.iloc[k, 4] == \"ovr\" and svm_res_cr.iloc[k, 1] == \"hinge\" and svm_res_cr.iloc[k, 2] == \"l2\" and svm_res_cr.iloc[k, 3] == True and svm_res_cr.iloc[k, 5] == None)], color= \"blue\")\n",
    "\n",
    "ax.set_xticks([i for i in range(5)], [0.001, 0.1 , 1, 10, 100])\n",
    "ax.grid(axis= 'x', which= 'major')\n",
    "\n",
    "colors= {'crammer_singer_bal':\"black\", 'ovr_bal':'green', \"crammer_singer_Nan\": \"brown\", \"ovr_Nan\": \"blue\"}\n",
    "label = list(colors.keys())\n",
    "handle = [plt.Rectangle((0,0),2,2, color=colors[lab]) for lab in label]\n",
    "\n",
    "ax.legend(handles= handle, labels= label, loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': 'balanced',\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1e-05,\n",
       " 'loss': 'squared_hinge',\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1'], \n",
    "          'loss':['squared_hinge'],\n",
    "          \"C\": [0.1 , 1],\n",
    "          'dual': [False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr'],\n",
    "          'intercept_scaling': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "            }\n",
    "\n",
    "gsi = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X1, y)\n",
    "gsi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_intercept_scaling</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.989039</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.989039</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.983483</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983483</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0      0.1  squared_hinge            l1      False               ovr   \n",
       "1      0.1  squared_hinge            l1      False               ovr   \n",
       "2        1  squared_hinge            l1      False               ovr   \n",
       "3        1  squared_hinge            l1      False               ovr   \n",
       "4        1  squared_hinge            l1      False               ovr   \n",
       "5        1  squared_hinge            l1      False               ovr   \n",
       "6        1  squared_hinge            l1      False               ovr   \n",
       "7        1  squared_hinge            l1      False               ovr   \n",
       "8        1  squared_hinge            l1      False               ovr   \n",
       "9        1  squared_hinge            l1      False               ovr   \n",
       "10     0.1  squared_hinge            l1      False               ovr   \n",
       "11     0.1  squared_hinge            l1      False               ovr   \n",
       "12       1  squared_hinge            l1      False               ovr   \n",
       "13     0.1  squared_hinge            l1      False               ovr   \n",
       "14     0.1  squared_hinge            l1      False               ovr   \n",
       "15     0.1  squared_hinge            l1      False               ovr   \n",
       "16     0.1  squared_hinge            l1      False               ovr   \n",
       "17     0.1  squared_hinge            l1      False               ovr   \n",
       "18     0.1  squared_hinge            l1      False               ovr   \n",
       "19     0.1  squared_hinge            l1      False               ovr   \n",
       "20     0.1  squared_hinge            l1      False               ovr   \n",
       "21       1  squared_hinge            l1      False               ovr   \n",
       "22       1  squared_hinge            l1      False               ovr   \n",
       "23       1  squared_hinge            l1      False               ovr   \n",
       "24       1  squared_hinge            l1      False               ovr   \n",
       "25       1  squared_hinge            l1      False               ovr   \n",
       "26     0.1  squared_hinge            l1      False               ovr   \n",
       "27     0.1  squared_hinge            l1      False               ovr   \n",
       "\n",
       "   param_class_weight param_intercept_scaling  mean_test_score  \\\n",
       "0            balanced                 0.00001         0.994444   \n",
       "1                None                       1         0.994444   \n",
       "2                None                       1         0.994444   \n",
       "3                None                     0.1         0.994444   \n",
       "4                None                    0.01         0.994444   \n",
       "5                None                  0.0001         0.994444   \n",
       "6            balanced                      10         0.994444   \n",
       "7            balanced                       1         0.994444   \n",
       "8            balanced                    0.01         0.994444   \n",
       "9            balanced                   0.001         0.994444   \n",
       "10           balanced                  0.0001         0.994444   \n",
       "11               None                      10         0.994444   \n",
       "12           balanced                 0.00001         0.994444   \n",
       "13               None                     0.1         0.994444   \n",
       "14               None                   0.001         0.994444   \n",
       "15               None                 0.00001         0.994444   \n",
       "16           balanced                      10         0.994444   \n",
       "17           balanced                     0.1         0.994444   \n",
       "18           balanced                   0.001         0.994444   \n",
       "19               None                  0.0001         0.989039   \n",
       "20           balanced                    0.01         0.989039   \n",
       "21           balanced                  0.0001         0.988889   \n",
       "22           balanced                     0.1         0.988889   \n",
       "23               None                 0.00001         0.988889   \n",
       "24               None                   0.001         0.988889   \n",
       "25               None                      10         0.988889   \n",
       "26               None                    0.01         0.983483   \n",
       "27           balanced                       1         0.983483   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "5                 1  \n",
       "6                 1  \n",
       "7                 1  \n",
       "8                 1  \n",
       "9                 1  \n",
       "10                1  \n",
       "11                1  \n",
       "12                1  \n",
       "13                1  \n",
       "14                1  \n",
       "15                1  \n",
       "16                1  \n",
       "17                1  \n",
       "18                1  \n",
       "19               20  \n",
       "20               20  \n",
       "21               22  \n",
       "22               22  \n",
       "23               22  \n",
       "24               22  \n",
       "25               22  \n",
       "26               27  \n",
       "27               27  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_i = pd.DataFrame(gsi.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"param_intercept_scaling\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_i.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_i.reset_index(drop= True, inplace=True)\n",
    "svm_res_i.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1'], \n",
    "          'loss':['squared_hinge'],\n",
    "          \"C\": [7, 8, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9],\n",
    "          'dual': [False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr'],\n",
    "          'intercept_scaling': [0.00001, 0.0001, 0.001, 0.01],\n",
    "          'max_iter': [10000]\n",
    "            }\n",
    "\n",
    "gsi = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X1, y)\n",
    "gsi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_intercept_scaling</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.9</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.3</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.5</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.6</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.7</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.7</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0      8.3  squared_hinge            l1      False               ovr   \n",
       "1      8.9  squared_hinge            l1      False               ovr   \n",
       "2      8.4  squared_hinge            l1      False               ovr   \n",
       "3        8  squared_hinge            l1      False               ovr   \n",
       "4      8.3  squared_hinge            l1      False               ovr   \n",
       "5      8.4  squared_hinge            l1      False               ovr   \n",
       "6      8.4  squared_hinge            l1      False               ovr   \n",
       "7      8.4  squared_hinge            l1      False               ovr   \n",
       "8      8.4  squared_hinge            l1      False               ovr   \n",
       "9      8.5  squared_hinge            l1      False               ovr   \n",
       "10     8.6  squared_hinge            l1      False               ovr   \n",
       "11     8.1  squared_hinge            l1      False               ovr   \n",
       "12     8.1  squared_hinge            l1      False               ovr   \n",
       "13     8.1  squared_hinge            l1      False               ovr   \n",
       "14     8.1  squared_hinge            l1      False               ovr   \n",
       "15     8.7  squared_hinge            l1      False               ovr   \n",
       "16     8.7  squared_hinge            l1      False               ovr   \n",
       "17       7  squared_hinge            l1      False               ovr   \n",
       "18       7  squared_hinge            l1      False               ovr   \n",
       "19       9  squared_hinge            l1      False               ovr   \n",
       "\n",
       "   param_class_weight param_intercept_scaling  mean_test_score  \\\n",
       "0                None                    0.01         0.994595   \n",
       "1                None                    0.01         0.994595   \n",
       "2                None                    0.01         0.994444   \n",
       "3                None                    0.01         0.994444   \n",
       "4            balanced                  0.0001         0.994444   \n",
       "5            balanced                  0.0001         0.994444   \n",
       "6                None                 0.00001         0.994444   \n",
       "7                None                  0.0001         0.994444   \n",
       "8                None                   0.001         0.994444   \n",
       "9                None                   0.001         0.994444   \n",
       "10           balanced                  0.0001         0.994444   \n",
       "11               None                  0.0001         0.994444   \n",
       "12           balanced                  0.0001         0.994444   \n",
       "13           balanced                 0.00001         0.994444   \n",
       "14           balanced                   0.001         0.994444   \n",
       "15           balanced                 0.00001         0.994444   \n",
       "16           balanced                   0.001         0.994444   \n",
       "17           balanced                   0.001         0.994444   \n",
       "18           balanced                    0.01         0.994444   \n",
       "19           balanced                 0.00001         0.994444   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 3  \n",
       "3                 3  \n",
       "4                 3  \n",
       "5                 3  \n",
       "6                 3  \n",
       "7                 3  \n",
       "8                 3  \n",
       "9                 3  \n",
       "10                3  \n",
       "11                3  \n",
       "12                3  \n",
       "13                3  \n",
       "14                3  \n",
       "15                3  \n",
       "16                3  \n",
       "17                3  \n",
       "18                3  \n",
       "19                3  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_c = pd.DataFrame(gsi.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"param_intercept_scaling\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_c.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_c.reset_index(drop= True, inplace=True)\n",
    "svm_res_c.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 99.4737%\n",
      "[0.94736842 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(C=8.9, penalty= 'l1', dual=False, multi_class='ovr', class_weight=None, intercept_scaling= 0.0001)\n",
    "cross = cross_val_score(svm, X1, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
