{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\\..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from fix_data import add_label_T\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcc_smarts_df_train = pd.read_csv(\"data/DropSeq/HCC1806_Filtered_Normalised_3000_Data_train.txt\", sep = \" \")\n",
    "mcf_smarts_df_train = pd.read_csv(\"data/DropSeq/MCF7_Filtered_Normalised_3000_Data_train.txt\", sep= \" \")\n",
    "\n",
    "hcc_smarts_df_train = add_label_T(hcc_smarts_df_train)\n",
    "mcf_smarts_df_train = add_label_T(mcf_smarts_df_train)\n",
    "\n",
    "X1 = hcc_smarts_df_train.loc[:,hcc_smarts_df_train.columns!='label']\n",
    "X2 = mcf_smarts_df_train.loc[:,mcf_smarts_df_train.columns!='label']\n",
    "y = mcf_smarts_df_train[\"label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 97.0175%\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "cross = cross_val_score(svm, X2, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "180 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.94289276        nan 0.9169518  0.41251271 0.94289276\n",
      "        nan        nan        nan 0.96814022        nan 0.95940071\n",
      " 0.83912839 0.96814022        nan        nan        nan 0.97835956\n",
      "        nan 0.97493766 0.95482259 0.97835956        nan        nan\n",
      "        nan 0.97470635        nan 0.97674097 0.98016272 0.97452137\n",
      "        nan        nan        nan 0.97008223        nan 0.96901867\n",
      " 0.97188564 0.96985107        nan        nan        nan 0.96883373\n",
      "        nan 0.96874124 0.96763151 0.96934238        nan        nan\n",
      "        nan 0.96883372        nan 0.968695   0.96772404 0.96938864\n",
      "        nan        nan        nan 0.96864876        nan 0.96855627\n",
      " 0.95856844 0.96934239        nan        nan        nan 0.96892621\n",
      "        nan 0.9683713  0.95805989 0.96920366        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1', 'l2'], \n",
    "          'loss':['squared_hinge', 'hinge'],\n",
    "          \"C\": [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000],\n",
    "          'dual': [True, False]\n",
    "            }\n",
    "\n",
    "gs_t = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X2, y)\n",
    "gs_t.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.976741</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.974938</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>10000</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual  mean_test_score  \\\n",
       "28     0.1  squared_hinge            l1      False         0.980163   \n",
       "17   0.001  squared_hinge            l2       True         0.978360   \n",
       "21   0.001  squared_hinge            l2      False         0.978360   \n",
       "27     0.1          hinge            l2       True         0.976741   \n",
       "19   0.001          hinge            l2       True         0.974938   \n",
       "..     ...            ...           ...        ...              ...   \n",
       "63    1000          hinge            l2      False              NaN   \n",
       "64   10000  squared_hinge            l1       True              NaN   \n",
       "66   10000          hinge            l1       True              NaN   \n",
       "70   10000          hinge            l1      False              NaN   \n",
       "71   10000          hinge            l2      False              NaN   \n",
       "\n",
       "    rank_test_score  \n",
       "28                1  \n",
       "17                2  \n",
       "21                2  \n",
       "27                4  \n",
       "19                5  \n",
       "..              ...  \n",
       "63               37  \n",
       "64               37  \n",
       "66               37  \n",
       "70               37  \n",
       "71               37  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_t = pd.DataFrame(gs_t.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_t.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_t.iloc[:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1e-05': 0.9428927602692685,\n",
       " '0.0001': 0.9681402248536205,\n",
       " '0.001': 0.9783595573478283,\n",
       " '0.1': 0.9801627155604372,\n",
       " '1': 0.971885643735018,\n",
       " '10': 0.9693423766498575,\n",
       " '100': 0.9693886408034228,\n",
       " '1000': 0.9693423873393568,\n",
       " '10000': 0.9692036590156574}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fit_true = {}\n",
    "for i in [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000]:\n",
    "    best_fit_true[f\"{i}\"] = max([svm_res_t.iloc[j,:].values for j in range(svm_res_t.shape[0]) if svm_res_t.iloc[j,0] == i], key= lambda x: x[4])[4]\n",
    "\n",
    "best_fit_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_res_t.sort_values(by=\"param_C\", ascending=True, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "\n",
    "\n",
    "ax.bar([i for i in range(0,18,2)], [i for k,i in  enumerate(svm_res_t.loc[:,\"mean_test_score\"]) if (svm_res_t.iloc[k, 1] == \"hinge\" and svm_res_t.iloc[k, 2] == \"l2\" and svm_res_t.iloc[k, 3] == True)], width= 0.25, color= \"steelblue\")\n",
    "ax.bar([i + 0.25 for i in range(0,18,2)], [i for k,i in  enumerate(svm_res_t.loc[:,\"mean_test_score\"]) if (svm_res_t.iloc[k, 1] == \"squared_hinge\" and svm_res_t.iloc[k, 2] == \"l2\" and svm_res_t.iloc[k, 3] == False)], width= 0.25, color= \"black\")\n",
    "ax.bar([i + 0.25 + 0.25 for i in range(0,18,2)], [i for k,i in  enumerate(svm_res_t.loc[:,\"mean_test_score\"]) if (svm_res_t.iloc[k, 1] == \"squared_hinge\" and svm_res_t.iloc[k, 2] == \"l2\" and svm_res_t.iloc[k, 3] == True)], width= 0.25, color= \"darkgreen\")\n",
    "ax.bar([i + 0.25 + 0.25 + 0.25 for i in range(0,18,2)], [i for k,i in  enumerate(svm_res_t.loc[:,\"mean_test_score\"]) if (svm_res_t.iloc[k, 1] == \"squared_hinge\" and svm_res_t.iloc[k, 2] == \"l1\" and svm_res_t.iloc[k, 3] == False)], width= 0.25, color= \"olivedrab\")\n",
    "\n",
    "ax.set_xticks([i + 0.385 for i in range(0,18,2)], [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000])\n",
    "\n",
    "ax.grid(axis= 'y', which= 'major', alpha=0.5)\n",
    "\n",
    "colors = {\"l2_hinge_dual\": \"steelblue\", \"l2_squared_hinge_primal\": \"black\", \"l2_squared_hinge_dual\": \"darkgreen\", \"l1_squared_hinge_primal\": \"olivedrab\"}\n",
    "label = list(colors.keys())\n",
    "handle = [plt.Rectangle((0,0),2,2, color=colors[lab]) for lab in label]\n",
    "\n",
    "ax.legend(handles= handle, labels= label, loc = \"lower left\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "180 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.94256908        nan 0.91690558 0.41251271 0.94256908\n",
      "        nan        nan        nan 0.9674004         nan 0.95852213\n",
      " 0.83912839 0.9674004         nan        nan        nan 0.97650982\n",
      "        nan 0.97345798 0.94492722 0.97655607        nan        nan\n",
      "        nan 0.9705909         nan 0.97359665 0.97646355 0.97072963\n",
      "        nan        nan        nan 0.96545825        nan 0.96485711\n",
      " 0.96818641 0.96555075        nan        nan        nan 0.96499581\n",
      "        nan 0.96504206 0.96726161 0.96494959        nan        nan\n",
      "        nan 0.96485709        nan 0.96485708 0.96661425 0.96457967\n",
      "        nan        nan        nan 0.96481085        nan 0.96504206\n",
      " 0.95722758 0.96471839        nan        nan        nan 0.96494957\n",
      "        nan 0.96485709 0.95801354 0.9643485         nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(fit_intercept = False)\n",
    "p_grid = {'penalty': ['l1', 'l2'], \n",
    "          'loss':['squared_hinge', 'hinge'],\n",
    "          \"C\": [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000],\n",
    "          'dual': [True, False]\n",
    "            }\n",
    "\n",
    "gs_f = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X2, y)\n",
    "gs_f.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.976556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.976510</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.976464</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.973597</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.973458</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10000</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual  mean_test_score  \\\n",
       "0    0.001  squared_hinge            l2      False         0.976556   \n",
       "1    0.001  squared_hinge            l2       True         0.976510   \n",
       "2      0.1  squared_hinge            l1      False         0.976464   \n",
       "3      0.1          hinge            l2       True         0.973597   \n",
       "4    0.001          hinge            l2       True         0.973458   \n",
       "..     ...            ...           ...        ...              ...   \n",
       "67    1000          hinge            l2      False              NaN   \n",
       "68   10000  squared_hinge            l1       True              NaN   \n",
       "69   10000          hinge            l1       True              NaN   \n",
       "70   10000          hinge            l1      False              NaN   \n",
       "71   10000          hinge            l2      False              NaN   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 3  \n",
       "3                 4  \n",
       "4                 5  \n",
       "..              ...  \n",
       "67               37  \n",
       "68               37  \n",
       "69               37  \n",
       "70               37  \n",
       "71               37  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_f = pd.DataFrame(gs_f.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_f.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_f.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_false = {}\n",
    "for i in [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000]:\n",
    "    best_fit_false[f\"{i}\"] = max([svm_res_f.iloc[j,:].values for j in range(svm_res_f.shape[0]) if svm_res_f.iloc[j,0] == i], key= lambda x: x[4])[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ig, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "ax.bar([i for i in range(9)], list(best_fit_true.values()), 0.25, color = \"black\")\n",
    "ax.bar([i + 0.25 for i in range(9)], list(best_fit_false.values()), 0.25, color = \"darkgreen\")\n",
    "\n",
    "ax.set_xticks([i + 0.125 for i in range(9)], [0.00001, 0.0001, 0.001, 0.1 , 1, 10, 100, 1000, 10000])\n",
    "ax.grid(axis= 'y', which= 'major', alpha=0.5)\n",
    "\n",
    "colors = {\"intercept_true\": \"black\", \"intercept_false\": \"darkgreen\"}\n",
    "label = list(colors.keys())\n",
    "handle = [plt.Rectangle((0,0),2,2, color=colors[lab]) for lab in label]\n",
    "\n",
    "ax.legend(handles= handle, labels= label, loc = \"lower left\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "120 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 274, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Samuele\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.9785445  0.97794339 0.97794339        nan 0.97540017\n",
      " 0.97794339 0.97794339 0.95482258 0.9785445  0.97794339 0.97794339\n",
      "        nan        nan 0.97794339 0.97794339        nan 0.97835956\n",
      " 0.97761965 0.97761965        nan 0.97493766 0.97761965 0.97761965\n",
      " 0.95482259 0.97835956 0.97761965 0.97761965        nan        nan\n",
      " 0.97761965 0.97761965        nan 0.97396652 0.97373527 0.97373527\n",
      "        nan 0.976741   0.97373527 0.97373527 0.9791917  0.97387402\n",
      " 0.97373527 0.97373527        nan        nan 0.97373527 0.97373527\n",
      "        nan 0.9746601  0.97405887 0.97405887        nan 0.97674097\n",
      " 0.97405887 0.97405887 0.98016272 0.97452137 0.97405887 0.97405887\n",
      "        nan        nan 0.97405887 0.97405887        nan 0.96994349\n",
      " 0.9690187  0.9690187         nan 0.96892621 0.9690187  0.9690187\n",
      " 0.97183943 0.96961987 0.9690187  0.9690187         nan        nan\n",
      " 0.9690187  0.9690187         nan 0.9699435  0.9690187  0.9690187\n",
      "        nan 0.96883371 0.9690187  0.9690187  0.97197815 0.96985107\n",
      " 0.9690187  0.9690187         nan        nan 0.9690187  0.9690187 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'loss': 'squared_hinge',\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1', 'l2'], \n",
    "          'loss':['squared_hinge', 'hinge'],\n",
    "          \"C\": [0.001, 0.1 , 1],\n",
    "          'dual': [True, False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr', 'crammer_singer']\n",
    "            }\n",
    "\n",
    "gs_cr = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X2, y)\n",
    "gs_cr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.980163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.979192</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.978544</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.978544</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.977943</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.977943</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.977943</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>crammer_singer</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.977943</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0     0.1  squared_hinge            l1      False               ovr   \n",
       "1     0.1  squared_hinge            l1      False               ovr   \n",
       "2   0.001  squared_hinge            l2      False               ovr   \n",
       "3   0.001  squared_hinge            l2       True               ovr   \n",
       "4   0.001  squared_hinge            l2      False               ovr   \n",
       "5   0.001  squared_hinge            l2       True               ovr   \n",
       "6   0.001          hinge            l1       True    crammer_singer   \n",
       "7   0.001  squared_hinge            l1       True    crammer_singer   \n",
       "8   0.001  squared_hinge            l2       True    crammer_singer   \n",
       "9   0.001  squared_hinge            l1      False    crammer_singer   \n",
       "\n",
       "  param_class_weight  mean_test_score  rank_test_score  \n",
       "0               None         0.980163                1  \n",
       "1           balanced         0.979192                2  \n",
       "2           balanced         0.978544                3  \n",
       "3           balanced         0.978544                3  \n",
       "4               None         0.978360                5  \n",
       "5               None         0.978360                5  \n",
       "6           balanced         0.977943                7  \n",
       "7           balanced         0.977943                7  \n",
       "8           balanced         0.977943                7  \n",
       "9           balanced         0.977943                7  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_cr = pd.DataFrame(gs_cr.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_cr.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_cr.reset_index(drop= True, inplace=True)\n",
    "svm_res_cr.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 10,\n",
       " 'loss': 'squared_hinge',\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1'], \n",
    "          'loss':['squared_hinge'],\n",
    "          \"C\": [0.1 , 1],\n",
    "          'dual': [False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr'],\n",
    "          'intercept_scaling': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "            }\n",
    "\n",
    "gsi = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X2, y)\n",
    "gsi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_intercept_scaling</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.980348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.979423</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979192</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.978776</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.976510</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.976510</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.976464</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.976464</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.976279</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.976279</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.976279</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.976279</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971978</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971608</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.970545</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.970313</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.968418</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.968371</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.968325</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.968233</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.968001</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.967909</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.967909</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.967909</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0      0.1  squared_hinge            l1      False               ovr   \n",
       "1      0.1  squared_hinge            l1      False               ovr   \n",
       "2      0.1  squared_hinge            l1      False               ovr   \n",
       "3      0.1  squared_hinge            l1      False               ovr   \n",
       "4      0.1  squared_hinge            l1      False               ovr   \n",
       "5      0.1  squared_hinge            l1      False               ovr   \n",
       "6      0.1  squared_hinge            l1      False               ovr   \n",
       "7      0.1  squared_hinge            l1      False               ovr   \n",
       "8      0.1  squared_hinge            l1      False               ovr   \n",
       "9      0.1  squared_hinge            l1      False               ovr   \n",
       "10     0.1  squared_hinge            l1      False               ovr   \n",
       "11     0.1  squared_hinge            l1      False               ovr   \n",
       "12     0.1  squared_hinge            l1      False               ovr   \n",
       "13     0.1  squared_hinge            l1      False               ovr   \n",
       "14       1  squared_hinge            l1      False               ovr   \n",
       "15       1  squared_hinge            l1      False               ovr   \n",
       "16       1  squared_hinge            l1      False               ovr   \n",
       "17       1  squared_hinge            l1      False               ovr   \n",
       "18       1  squared_hinge            l1      False               ovr   \n",
       "19       1  squared_hinge            l1      False               ovr   \n",
       "20       1  squared_hinge            l1      False               ovr   \n",
       "21       1  squared_hinge            l1      False               ovr   \n",
       "22       1  squared_hinge            l1      False               ovr   \n",
       "23       1  squared_hinge            l1      False               ovr   \n",
       "24       1  squared_hinge            l1      False               ovr   \n",
       "25       1  squared_hinge            l1      False               ovr   \n",
       "26       1  squared_hinge            l1      False               ovr   \n",
       "27       1  squared_hinge            l1      False               ovr   \n",
       "\n",
       "   param_class_weight param_intercept_scaling  mean_test_score  \\\n",
       "0                None                      10         0.980348   \n",
       "1                None                       1         0.980163   \n",
       "2                None                     0.1         0.979423   \n",
       "3            balanced                       1         0.979192   \n",
       "4            balanced                      10         0.979099   \n",
       "5            balanced                     0.1         0.978776   \n",
       "6                None                 0.00001         0.976510   \n",
       "7                None                   0.001         0.976510   \n",
       "8                None                  0.0001         0.976464   \n",
       "9                None                    0.01         0.976464   \n",
       "10           balanced                  0.0001         0.976279   \n",
       "11           balanced                 0.00001         0.976279   \n",
       "12           balanced                    0.01         0.976279   \n",
       "13           balanced                   0.001         0.976279   \n",
       "14               None                       1         0.971978   \n",
       "15           balanced                      10         0.971839   \n",
       "16           balanced                       1         0.971793   \n",
       "17               None                      10         0.971608   \n",
       "18           balanced                     0.1         0.970545   \n",
       "19               None                     0.1         0.970313   \n",
       "20               None                   0.001         0.968418   \n",
       "21               None                    0.01         0.968371   \n",
       "22               None                  0.0001         0.968325   \n",
       "23               None                 0.00001         0.968233   \n",
       "24           balanced                    0.01         0.968001   \n",
       "25           balanced                   0.001         0.967909   \n",
       "26           balanced                  0.0001         0.967909   \n",
       "27           balanced                 0.00001         0.967909   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 3  \n",
       "3                 4  \n",
       "4                 5  \n",
       "5                 6  \n",
       "6                 7  \n",
       "7                 7  \n",
       "8                 9  \n",
       "9                 9  \n",
       "10               11  \n",
       "11               11  \n",
       "12               11  \n",
       "13               11  \n",
       "14               15  \n",
       "15               16  \n",
       "16               17  \n",
       "17               18  \n",
       "18               19  \n",
       "19               20  \n",
       "20               21  \n",
       "21               22  \n",
       "22               23  \n",
       "23               24  \n",
       "24               25  \n",
       "25               26  \n",
       "26               26  \n",
       "27               26  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_i = pd.DataFrame(gsi.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"param_intercept_scaling\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_i.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_i.reset_index(drop= True, inplace=True)\n",
    "svm_res_i.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 20,\n",
       " 'loss': 'squared_hinge',\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1'], \n",
    "          'loss':['squared_hinge'],\n",
    "          \"C\": [0.1 , 1],\n",
    "          'dual': [False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr'],\n",
    "          'intercept_scaling': [10, 20, 30, 40, 50]\n",
    "            }\n",
    "\n",
    "gsi = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X2, y)\n",
    "gsi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_intercept_scaling</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.979145</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>30</td>\n",
       "      <td>0.979145</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>40</td>\n",
       "      <td>0.979145</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>0.979145</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>0.971932</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>50</td>\n",
       "      <td>0.971886</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>30</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971747</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>40</td>\n",
       "      <td>0.971423</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>0.971285</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0      0.1  squared_hinge            l1      False               ovr   \n",
       "1      0.1  squared_hinge            l1      False               ovr   \n",
       "2      0.1  squared_hinge            l1      False               ovr   \n",
       "3      0.1  squared_hinge            l1      False               ovr   \n",
       "4      0.1  squared_hinge            l1      False               ovr   \n",
       "5      0.1  squared_hinge            l1      False               ovr   \n",
       "6      0.1  squared_hinge            l1      False               ovr   \n",
       "7      0.1  squared_hinge            l1      False               ovr   \n",
       "8      0.1  squared_hinge            l1      False               ovr   \n",
       "9      0.1  squared_hinge            l1      False               ovr   \n",
       "10       1  squared_hinge            l1      False               ovr   \n",
       "11       1  squared_hinge            l1      False               ovr   \n",
       "12       1  squared_hinge            l1      False               ovr   \n",
       "13       1  squared_hinge            l1      False               ovr   \n",
       "14       1  squared_hinge            l1      False               ovr   \n",
       "15       1  squared_hinge            l1      False               ovr   \n",
       "16       1  squared_hinge            l1      False               ovr   \n",
       "17       1  squared_hinge            l1      False               ovr   \n",
       "18       1  squared_hinge            l1      False               ovr   \n",
       "19       1  squared_hinge            l1      False               ovr   \n",
       "\n",
       "   param_class_weight param_intercept_scaling  mean_test_score  \\\n",
       "0                None                      20         0.980301   \n",
       "1                None                      30         0.980301   \n",
       "2                None                      40         0.980301   \n",
       "3                None                      50         0.980301   \n",
       "4                None                      10         0.980301   \n",
       "5            balanced                      20         0.979145   \n",
       "6            balanced                      30         0.979145   \n",
       "7            balanced                      40         0.979145   \n",
       "8            balanced                      50         0.979145   \n",
       "9            balanced                      10         0.979099   \n",
       "10               None                      50         0.971932   \n",
       "11           balanced                      50         0.971886   \n",
       "12               None                      30         0.971839   \n",
       "13           balanced                      10         0.971839   \n",
       "14           balanced                      30         0.971793   \n",
       "15           balanced                      20         0.971793   \n",
       "16               None                      20         0.971793   \n",
       "17               None                      10         0.971747   \n",
       "18           balanced                      40         0.971423   \n",
       "19               None                      40         0.971285   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 5  \n",
       "5                 6  \n",
       "6                 6  \n",
       "7                 6  \n",
       "8                 6  \n",
       "9                10  \n",
       "10               11  \n",
       "11               12  \n",
       "12               13  \n",
       "13               13  \n",
       "14               15  \n",
       "15               16  \n",
       "16               17  \n",
       "17               18  \n",
       "18               19  \n",
       "19               20  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_i = pd.DataFrame(gsi.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"param_intercept_scaling\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_i.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_i.reset_index(drop= True, inplace=True)\n",
    "svm_res_i.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 10,\n",
       " 'loss': 'squared_hinge',\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1'], \n",
    "          'loss':['squared_hinge'],\n",
    "          \"C\": [0.1 , 1],\n",
    "          'dual': [False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr'],\n",
    "          'intercept_scaling': [10, 11, 12, 13, 14, 15]\n",
    "            }\n",
    "\n",
    "gsi = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X2, y)\n",
    "gsi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_intercept_scaling</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>0.980348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>0.980348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>0.980348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.980348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>14</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>11</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>15</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>14</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>13</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>12</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>12</td>\n",
       "      <td>0.972071</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>13</td>\n",
       "      <td>0.971932</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971839</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>15</td>\n",
       "      <td>0.971747</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>14</td>\n",
       "      <td>0.971747</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>14</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>0.971654</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>0.971608</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>0.971608</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>11</td>\n",
       "      <td>0.971562</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0      0.1  squared_hinge            l1      False               ovr   \n",
       "1      0.1  squared_hinge            l1      False               ovr   \n",
       "2      0.1  squared_hinge            l1      False               ovr   \n",
       "3      0.1  squared_hinge            l1      False               ovr   \n",
       "4      0.1  squared_hinge            l1      False               ovr   \n",
       "5      0.1  squared_hinge            l1      False               ovr   \n",
       "6      0.1  squared_hinge            l1      False               ovr   \n",
       "7      0.1  squared_hinge            l1      False               ovr   \n",
       "8      0.1  squared_hinge            l1      False               ovr   \n",
       "9      0.1  squared_hinge            l1      False               ovr   \n",
       "10     0.1  squared_hinge            l1      False               ovr   \n",
       "11     0.1  squared_hinge            l1      False               ovr   \n",
       "12       1  squared_hinge            l1      False               ovr   \n",
       "13       1  squared_hinge            l1      False               ovr   \n",
       "14       1  squared_hinge            l1      False               ovr   \n",
       "15       1  squared_hinge            l1      False               ovr   \n",
       "16       1  squared_hinge            l1      False               ovr   \n",
       "17       1  squared_hinge            l1      False               ovr   \n",
       "18       1  squared_hinge            l1      False               ovr   \n",
       "19       1  squared_hinge            l1      False               ovr   \n",
       "20       1  squared_hinge            l1      False               ovr   \n",
       "21       1  squared_hinge            l1      False               ovr   \n",
       "22       1  squared_hinge            l1      False               ovr   \n",
       "23       1  squared_hinge            l1      False               ovr   \n",
       "\n",
       "   param_class_weight param_intercept_scaling  mean_test_score  \\\n",
       "0                None                      12         0.980348   \n",
       "1                None                      11         0.980348   \n",
       "2                None                      13         0.980348   \n",
       "3                None                      10         0.980348   \n",
       "4                None                      15         0.980301   \n",
       "5                None                      14         0.980301   \n",
       "6            balanced                      11         0.979099   \n",
       "7            balanced                      10         0.979099   \n",
       "8            balanced                      15         0.979099   \n",
       "9            balanced                      14         0.979099   \n",
       "10           balanced                      13         0.979099   \n",
       "11           balanced                      12         0.979099   \n",
       "12           balanced                      12         0.972071   \n",
       "13           balanced                      13         0.971932   \n",
       "14               None                      10         0.971839   \n",
       "15           balanced                      15         0.971747   \n",
       "16           balanced                      14         0.971747   \n",
       "17           balanced                      10         0.971654   \n",
       "18               None                      11         0.971654   \n",
       "19               None                      14         0.971654   \n",
       "20               None                      13         0.971654   \n",
       "21               None                      12         0.971608   \n",
       "22               None                      15         0.971608   \n",
       "23           balanced                      11         0.971562   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 5  \n",
       "5                 5  \n",
       "6                 7  \n",
       "7                 7  \n",
       "8                 7  \n",
       "9                 7  \n",
       "10                7  \n",
       "11                7  \n",
       "12               13  \n",
       "13               14  \n",
       "14               15  \n",
       "15               16  \n",
       "16               17  \n",
       "17               18  \n",
       "18               19  \n",
       "19               19  \n",
       "20               21  \n",
       "21               22  \n",
       "22               22  \n",
       "23               24  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_i = pd.DataFrame(gsi.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"param_intercept_scaling\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_i.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_i.reset_index(drop= True, inplace=True)\n",
    "svm_res_i.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 10,\n",
       " 'loss': 'squared_hinge',\n",
       " 'max_iter': 10000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1'], \n",
    "          'loss':['squared_hinge'],\n",
    "          \"C\": [0.1, 0.05, 0.15, 0.2, 0.3, 0.4],\n",
    "          'dual': [False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr'],\n",
    "          'intercept_scaling': [1, 10],\n",
    "          'max_iter': [10000]\n",
    "            }\n",
    "\n",
    "gsi = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X2, y)\n",
    "gsi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_intercept_scaling</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.980348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979747</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979284</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979192</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.15</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.978591</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.15</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978313</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.15</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978128</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.15</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.978082</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.976741</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976602</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.2</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976510</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.2</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.976417</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.3</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975631</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.3</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975539</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975076</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.3</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975076</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975030</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.3</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975030</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974614</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.4</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.974521</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0      0.1  squared_hinge            l1      False               ovr   \n",
       "1      0.1  squared_hinge            l1      False               ovr   \n",
       "2     0.05  squared_hinge            l1      False               ovr   \n",
       "3     0.05  squared_hinge            l1      False               ovr   \n",
       "4     0.05  squared_hinge            l1      False               ovr   \n",
       "5      0.1  squared_hinge            l1      False               ovr   \n",
       "6     0.05  squared_hinge            l1      False               ovr   \n",
       "7      0.1  squared_hinge            l1      False               ovr   \n",
       "8     0.15  squared_hinge            l1      False               ovr   \n",
       "9     0.15  squared_hinge            l1      False               ovr   \n",
       "10    0.15  squared_hinge            l1      False               ovr   \n",
       "11    0.15  squared_hinge            l1      False               ovr   \n",
       "12     0.2  squared_hinge            l1      False               ovr   \n",
       "13     0.2  squared_hinge            l1      False               ovr   \n",
       "14     0.2  squared_hinge            l1      False               ovr   \n",
       "15     0.2  squared_hinge            l1      False               ovr   \n",
       "16     0.3  squared_hinge            l1      False               ovr   \n",
       "17     0.3  squared_hinge            l1      False               ovr   \n",
       "18     0.4  squared_hinge            l1      False               ovr   \n",
       "19     0.3  squared_hinge            l1      False               ovr   \n",
       "20     0.4  squared_hinge            l1      False               ovr   \n",
       "21     0.3  squared_hinge            l1      False               ovr   \n",
       "22     0.4  squared_hinge            l1      False               ovr   \n",
       "23     0.4  squared_hinge            l1      False               ovr   \n",
       "\n",
       "   param_class_weight param_intercept_scaling  mean_test_score  \\\n",
       "0                None                      10         0.980348   \n",
       "1                None                       1         0.980163   \n",
       "2                None                      10         0.979885   \n",
       "3                None                       1         0.979747   \n",
       "4            balanced                      10         0.979284   \n",
       "5            balanced                       1         0.979192   \n",
       "6            balanced                       1         0.979099   \n",
       "7            balanced                      10         0.979099   \n",
       "8                None                      10         0.978591   \n",
       "9                None                       1         0.978313   \n",
       "10           balanced                       1         0.978128   \n",
       "11           balanced                      10         0.978082   \n",
       "12               None                      10         0.976741   \n",
       "13               None                       1         0.976602   \n",
       "14           balanced                       1         0.976510   \n",
       "15           balanced                      10         0.976417   \n",
       "16               None                       1         0.975631   \n",
       "17               None                      10         0.975539   \n",
       "18               None                      10         0.975076   \n",
       "19           balanced                       1         0.975076   \n",
       "20               None                       1         0.975030   \n",
       "21           balanced                      10         0.975030   \n",
       "22           balanced                       1         0.974614   \n",
       "23           balanced                      10         0.974521   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 2  \n",
       "2                 3  \n",
       "3                 4  \n",
       "4                 5  \n",
       "5                 6  \n",
       "6                 7  \n",
       "7                 8  \n",
       "8                 9  \n",
       "9                10  \n",
       "10               11  \n",
       "11               12  \n",
       "12               13  \n",
       "13               14  \n",
       "14               15  \n",
       "15               16  \n",
       "16               17  \n",
       "17               18  \n",
       "18               19  \n",
       "19               20  \n",
       "20               21  \n",
       "21               22  \n",
       "22               23  \n",
       "23               24  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_i = pd.DataFrame(gsi.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"param_intercept_scaling\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_i.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_i.reset_index(drop= True, inplace=True)\n",
    "svm_res_i.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.08,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 10,\n",
       " 'loss': 'squared_hinge',\n",
       " 'max_iter': 10000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "p_grid = {'penalty': ['l1'], \n",
    "          'loss':['squared_hinge'],\n",
    "          \"C\": [0.1, 0.06, 0.07, 0.08, 0.09],\n",
    "          'dual': [False],\n",
    "          'fit_intercept': [True],\n",
    "          'class_weight': ['balanced', None],\n",
    "          'multi_class': ['ovr'],\n",
    "          'intercept_scaling': [10],\n",
    "          'max_iter': [10000]\n",
    "            }\n",
    "\n",
    "gsi = GridSearchCV(svm, param_grid = p_grid, cv=5, scoring= 'accuracy').fit(X2, y)\n",
    "gsi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_intercept_scaling</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.980209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.07</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.08</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979469</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.09</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979423</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.06</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979330</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.07</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979238</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10</td>\n",
       "      <td>0.979099</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C     param_loss param_penalty param_dual param_multi_class  \\\n",
       "0    0.08  squared_hinge            l1      False               ovr   \n",
       "1     0.1  squared_hinge            l1      False               ovr   \n",
       "2    0.09  squared_hinge            l1      False               ovr   \n",
       "3    0.07  squared_hinge            l1      False               ovr   \n",
       "4    0.06  squared_hinge            l1      False               ovr   \n",
       "5    0.08  squared_hinge            l1      False               ovr   \n",
       "6    0.09  squared_hinge            l1      False               ovr   \n",
       "7    0.06  squared_hinge            l1      False               ovr   \n",
       "8    0.07  squared_hinge            l1      False               ovr   \n",
       "9     0.1  squared_hinge            l1      False               ovr   \n",
       "\n",
       "  param_class_weight param_intercept_scaling  mean_test_score  rank_test_score  \n",
       "0               None                      10         0.980301                1  \n",
       "1               None                      10         0.980301                2  \n",
       "2               None                      10         0.980209                3  \n",
       "3               None                      10         0.979885                4  \n",
       "4               None                      10         0.979885                5  \n",
       "5           balanced                      10         0.979469                6  \n",
       "6           balanced                      10         0.979423                7  \n",
       "7           balanced                      10         0.979330                8  \n",
       "8           balanced                      10         0.979238                9  \n",
       "9           balanced                      10         0.979099               10  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_i = pd.DataFrame(gsi.cv_results_)[[\"param_C\", \"param_loss\", \"param_penalty\", \"param_dual\", \"param_multi_class\", \"param_class_weight\", \"param_intercept_scaling\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_i.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_i.reset_index(drop= True, inplace=True)\n",
    "svm_res_i.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 98.0533%\n",
      "[0.98104485 0.9801202  0.9778086  0.9778086  0.97503467 0.98335645\n",
      " 0.98704903 0.97964847 0.98011101 0.98334875]\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.1, penalty= 'l1', dual=False, multi_class='ovr', class_weight=None, intercept_scaling= 10, max_iter= 10000)\n",
    "cross = cross_val_score(svm, X2, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 98.1273%\n",
      "[0.97827092 0.98196949 0.98335645 0.97965788 0.97364771 0.98566805\n",
      " 0.98751156 0.98057354 0.98057354 0.98149861]\n"
     ]
    }
   ],
   "source": [
    "nlsvm = SVC()\n",
    "cross = cross_val_score(nlsvm, X2, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X2, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 97.9932%\n",
      "[0.974122   0.98336414 0.97781885 0.97964847 0.98334875 0.98149861\n",
      " 0.98057354 0.97964847 0.98519889 0.97409806]\n"
     ]
    }
   ],
   "source": [
    "nlsvm = SVC()\n",
    "cross = cross_val_score(nlsvm, x_train, y_train, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "p_grid = {'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "          \"C\": [0.001, 0.1 , 1, 10, 100],\n",
    "            }\n",
    "\n",
    "gsin = GridSearchCV(svm, param_grid = p_grid, cv=2, scoring= 'accuracy', verbose= True ).fit(x_train, y_train)\n",
    "gsin.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.979839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.979747</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.975678</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.975030</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.972810</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.955794</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.951262</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.916675</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.878849</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.848516</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.836216</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.830112</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.615278</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.589383</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.589383</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_kernel  mean_test_score  rank_test_score\n",
       "0       10          rbf         0.979839                1\n",
       "1      100          rbf         0.979747                2\n",
       "2        1          rbf         0.975678                3\n",
       "3      100         poly         0.975030                4\n",
       "4       10         poly         0.972810                5\n",
       "5      0.1          rbf         0.955794                6\n",
       "6        1         poly         0.951262                7\n",
       "7      0.1      sigmoid         0.916675                8\n",
       "8      0.1         poly         0.878849                9\n",
       "9        1      sigmoid         0.848516               10\n",
       "10      10      sigmoid         0.836216               11\n",
       "11     100      sigmoid         0.830112               12\n",
       "12   0.001         poly         0.615278               13\n",
       "13   0.001          rbf         0.589383               14\n",
       "14   0.001      sigmoid         0.589383               14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_n = pd.DataFrame(gsin.cv_results_)[[\"param_C\", \"param_kernel\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_n.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_n.reset_index(drop= True, inplace=True)\n",
    "svm_res_n.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.001': 0.6152776292443969,\n",
       " '0.1': 0.9557940368745493,\n",
       " '1': 0.9756775534051343,\n",
       " '10': 0.979839219257918,\n",
       " '100': 0.9797467465373705}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fit = {}\n",
    "for i in [0.001, 0.1 , 1, 10, 100]:\n",
    "    best_fit[f\"{i}\"] = max([svm_res_n.iloc[j,:].values for j in range(svm_res_n.shape[0]) if svm_res_n.iloc[j,0] == i], key= lambda x: x[2])[2]\n",
    "\n",
    "best_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_res_n.sort_values(by=\"param_C\", ascending=True, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "\n",
    "best = max(best_fit.values())\n",
    "\n",
    "ax.bar([i for i in range(0,10,2)], [i for k,i in  enumerate(svm_res_n.loc[:,\"mean_test_score\"]) if svm_res_n.iloc[k, 1] == \"rbf\"], width= 0.25, color= \"steelblue\")\n",
    "ax.bar([i + 0.25 for i in range(0,10,2)], [i for k,i in  enumerate(svm_res_n.loc[:,\"mean_test_score\"]) if svm_res_n.iloc[k, 1] == \"poly\"], width= 0.25, color= \"black\")\n",
    "ax.bar([i + 0.25 + 0.25 for i in range(0,10,2)], [i for k,i in  enumerate(svm_res_n.loc[:,\"mean_test_score\"]) if svm_res_n.iloc[k, 1] == \"sigmoid\"], width= 0.25, color= \"darkgreen\")\n",
    "ax.axhline(y=best, color='green', linestyle='--')\n",
    "\n",
    "ax.set_xticks([i + 0.385 for i in range(0,10,2)], [0.001, 0.1 , 1, 10, 100])\n",
    "\n",
    "ax.grid(axis= 'y', which= 'major', alpha=0.5)\n",
    "\n",
    "colors = {\"rbf\": \"steelblue\", \"poly\": \"black\", \"sigmoid\": \"darkgreen\"}\n",
    "label = list(colors.keys())\n",
    "handle = [plt.Rectangle((0,0),2,2, color=colors[lab]) for lab in label]\n",
    "\n",
    "ax.legend(handles= handle, labels= label, loc = \"lower left\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'degree': 2, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "p_grid = {'kernel': ['poly'],\n",
    "          \"C\": [1, 10, 100],\n",
    "          \"degree\": [2, 4, 5]\n",
    "            }\n",
    "\n",
    "gsin = GridSearchCV(svm, param_grid = p_grid, cv=2, scoring= 'accuracy', verbose= True ).fit(x_train, y_train)\n",
    "gsin.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977157</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.971331</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.962360</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.950060</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944048</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.903357</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.860168</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_degree  mean_test_score  rank_test_score\n",
       "0      10            2         0.977527                1\n",
       "1     100            2         0.977157                2\n",
       "2       1            2         0.971331                3\n",
       "3     100            4         0.962360                4\n",
       "4      10            4         0.950060                5\n",
       "5     100            5         0.944048                6\n",
       "6      10            5         0.917969                7\n",
       "7       1            4         0.903357                8\n",
       "8       1            5         0.860168                9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_np = pd.DataFrame(gsin.cv_results_)[[\"param_C\", \"param_degree\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_np.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_np.reset_index(drop= True, inplace=True)\n",
    "svm_res_np.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_res_np.sort_values(by=\"param_C\", ascending=True, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "\n",
    "# best = max(best_fit.values())\n",
    "\n",
    "ax.bar([i for i in range(0,6,2)], [i for k,i in  enumerate(svm_res_np.loc[:,\"mean_test_score\"]) if svm_res_np.iloc[k, 1] == 2], width= 0.25, color= \"steelblue\")\n",
    "ax.bar([i + 0.25 for i in range(0,6,2)], [i for k,i in  enumerate(svm_res_np.loc[:,\"mean_test_score\"]) if svm_res_np.iloc[k, 1] == 4], width= 0.25, color= \"black\")\n",
    "ax.bar([i + 0.25 + 0.25 for i in range(0,6,2)], [i for k,i in  enumerate(svm_res_np.loc[:,\"mean_test_score\"]) if svm_res_np.iloc[k, 1] == 5], width= 0.25, color= \"darkgreen\")\n",
    "# ax.axhline(y=best, color='green', linestyle='--')\n",
    "\n",
    "ax.set_xticks([i + 0.385 for i in range(0,6,2)], [1, 10, 100])\n",
    "\n",
    "ax.grid(axis= 'y', which= 'major', alpha=0.5)\n",
    "\n",
    "colors = {\"2\": \"steelblue\", \"4\": \"black\", \"5\": \"darkgreen\"}\n",
    "label = list(colors.keys())\n",
    "handle = [plt.Rectangle((0,0),2,2, color=colors[lab]) for lab in label]\n",
    "\n",
    "ax.legend(handles= handle, labels= label, loc = \"lower left\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.9713306513165372, '10': 0.9775267170213644, '100': 0.9771568432447463}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fit_d = {}\n",
    "for i in [1, 10, 100]:\n",
    "    best_fit_d[f\"{i}\"] = max([svm_res_np.iloc[j,:].values for j in range(svm_res_np.shape[0]) if svm_res_np.iloc[j,0] == i], key= lambda x: x[2])[2]\n",
    "\n",
    "best_fit_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit = [0.9756775534051343, 0.979839219257918, 0.9797467465373705]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "ax.bar([i for i in range(3)], best_fit, 0.25, color = \"black\")\n",
    "ax.bar([i + 0.25 for i in range(3)], list(best_fit_d.values()), 0.25, color = \"darkgreen\")\n",
    "\n",
    "best = max([*[i for i in best_fit], *[i for i in best_fit_d.values()]])\n",
    "\n",
    "ax.set_xticks([i + 0.125 for i in range(3)], [1, 10, 100])\n",
    "ax.grid(axis= 'y', which= 'major', alpha=0.5)\n",
    "ax.axhline(y=best, color='green', linestyle='--')\n",
    "\n",
    "colors = {\"rbf\": \"black\", \"poly\": \"darkgreen\"}\n",
    "label = list(colors.keys())\n",
    "handle = [plt.Rectangle((0,0),2,2, color=colors[lab]) for lab in label]\n",
    "\n",
    "ax.legend(handles= handle, labels= label, loc = \"lower left\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "p_grid = {'kernel': ['poly', 'rbf'],\n",
    "          \"degree\": [2],\n",
    "          \"C\": [1, 10, 100],\n",
    "          \"gamma\": [\"scale\", \"auto\"]\n",
    "            }\n",
    "\n",
    "gsin = GridSearchCV(svm, param_grid = p_grid, cv=2, scoring= 'accuracy', verbose= True ).fit(x_train, y_train)\n",
    "gsin.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.977527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.977527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.977527</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poly</td>\n",
       "      <td>100</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.977157</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.975770</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.973550</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.972995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.971331</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poly</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.970776</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.965874</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>poly</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.922871</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.799315</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_kernel param_C param_gamma  mean_test_score  rank_test_score\n",
       "0           rbf      10       scale         0.977527                1\n",
       "1           rbf     100       scale         0.977527                1\n",
       "2          poly      10       scale         0.977527                3\n",
       "3          poly     100       scale         0.977157                4\n",
       "4           rbf      10        auto         0.975770                5\n",
       "5           rbf     100        auto         0.973550                6\n",
       "6           rbf       1       scale         0.972995                7\n",
       "7          poly       1       scale         0.971331                8\n",
       "8          poly     100        auto         0.970776                9\n",
       "9           rbf       1        auto         0.965874               10\n",
       "10         poly      10        auto         0.922871               11\n",
       "11         poly       1        auto         0.799315               12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_npg = pd.DataFrame(gsin.cv_results_)[[\"param_kernel\", \"param_C\", \"param_gamma\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_npg.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_npg.reset_index(drop= True, inplace=True)\n",
    "svm_res_npg.iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 72500, 'gamma': 1e-07, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "p_grid = {'kernel': ['rbf'],\n",
    "          \"C\": [75000, 72500, 77500],\n",
    "          \"gamma\": [0.0000001]\n",
    "            }\n",
    "\n",
    "gsin = GridSearchCV(svm, param_grid = p_grid, cv=2, scoring= 'accuracy', verbose= True ).fit(x_train, y_train)\n",
    "gsin.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>72500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>75000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979007</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rbf</td>\n",
       "      <td>77500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979007</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_kernel param_C param_gamma  mean_test_score  rank_test_score\n",
       "0          rbf   72500         0.0         0.979007                1\n",
       "1          rbf   75000         0.0         0.979007                2\n",
       "2          rbf   77500         0.0         0.979007                2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_res_npg = pd.DataFrame(gsin.cv_results_)[[\"param_kernel\", \"param_C\", \"param_gamma\", \"mean_test_score\", \"rank_test_score\"]]\n",
    "svm_res_npg.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
    "svm_res_npg.reset_index(drop= True, inplace=True)\n",
    "svm_res_npg.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 98.0301%\n",
      "[0.97781885 0.98798521 0.98336414 0.98057354 0.9759482  0.98334875\n",
      " 0.98057354 0.98334875 0.97502313 0.97502313]\n"
     ]
    }
   ],
   "source": [
    "nlsvm = SVC(C= 72500, gamma= 0.0000001)\n",
    "cross = cross_val_score(nlsvm, x_train, y_train, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9783593822250994\n"
     ]
    }
   ],
   "source": [
    "nlsvm.fit(x_train,y_train)\n",
    "y_hat = nlsvm.predict(x_test)\n",
    "print(\"Accuracy =\", accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlsvm = SVC(C= 72500, gamma= 0.0000001)\n",
    "cross = cross_val_score(nlsvm, X2, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X2, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 98.0117%\n",
      "[0.97965788 0.97873324 0.98104485 0.9778086  0.97272307 0.98289413\n",
      " 0.98566142 0.98057354 0.9787234  0.98334875]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2244/1815057219.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "nlsvm = SVC(C= 72500, gamma= 0.0000001)\n",
    "cross = cross_val_score(nlsvm, X2, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)\n",
    "\n",
    "nlsvm.fit(x_train, y_train)\n",
    "\n",
    "print(tools.model_metrics(nlsvm, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 98.2105%\n",
      "[0.98150717 0.98474341 0.98150717 0.97873324 0.97549699 0.98566805\n",
      " 0.98704903 0.98334875 0.97826087 0.98473636]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2244/2102111442.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnlsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "nlsvm = SVC(C= 10)\n",
    "cross = cross_val_score(nlsvm, X2, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)\n",
    "\n",
    "nlsvm.fit(x_train, y_train)\n",
    "\n",
    "print(tools.model_metrics(nlsvm, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9817383263985205, 0.983024082116068, 0.9857482185273159)\n",
      "(0.9803513638465094, 0.9807010634107917, 0.9857482185273159)\n"
     ]
    }
   ],
   "source": [
    "nlsvm = SVC(C= 72500, gamma= 0.0000001)\n",
    "nlsvm.fit(x_train, y_train)\n",
    "print(tools.model_metrics(nlsvm, x_test, y_test))\n",
    "\n",
    "nlsvm = SVC(C= 10)\n",
    "nlsvm.fit(x_train, y_train)\n",
    "print(tools.model_metrics(nlsvm, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 98.0533%\n",
      "[0.98104485 0.9801202  0.9778086  0.9778086  0.97503467 0.98335645\n",
      " 0.98704903 0.97964847 0.98011101 0.98334875]\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.1, penalty= 'l1', dual=False, multi_class='ovr', class_weight=None, intercept_scaling= 10, max_iter= 10000)\n",
    "cross = cross_val_score(svm, X2, y, scoring=\"accuracy\", cv=10)\n",
    "print(f\"Final accuracy = {round((sum(cross) / 10) * 100, 4)}%\")\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9803513638465094, 0.9807010634107917, 0.9857482185273159)\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.1, penalty= 'l1', dual=False, multi_class='ovr', class_weight=None, intercept_scaling= 10, max_iter= 10000)\n",
    "svm.fit(x_train, y_train)\n",
    "print(tools.model_metrics(nlsvm, x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
